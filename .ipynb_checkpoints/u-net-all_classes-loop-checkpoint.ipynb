{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### U-Net architecture\n",
    "\n",
    "See [here](https://github.com/jocicmarko/ultrasound-nerve-segmentation/blob/master/train.py#L19) for code and [here](https://arxiv.org/pdf/1505.04597.pdf) for the original literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def restart_kernel(restart=False):\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    if restart:\n",
    "        app.kernel.do_shutdown(True)\n",
    "\n",
    "restart_kernel(False)\n",
    "\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu,lib.cnmem=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5105)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Reshape, Input, merge, Activation, Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Cropping2D, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adadelta, Adam\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "K.set_image_dim_ordering('th')  # Theano dimension ordering in this code\n",
    "# \"tf\" assumes (rows, cols, channels) while \"th\" assumes (channels, rows, cols)\n",
    "# Possibly change this around natively in the data so the backend doesn't have to switch them\n",
    "# Only necessary if I use TF!\n",
    "\n",
    "import skimage.exposure\n",
    "import cv2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pushbullet import Pushbullet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is run # 124\n"
     ]
    }
   ],
   "source": [
    "# Pushbullet notifier\n",
    "def push(title='Done!',text=''):\n",
    "    Pushbullet('o.YFPNNPfGRekivaCGHa4qMSgjZt8zJ6FL').devices[0].push_note(title,text)\n",
    "    \n",
    "# Import the training data\n",
    "def import_data(img_h,img_w):\n",
    "    \n",
    "    x_train = np.load('./data/training-data/tiled_patched_images_576_576_train.npy')\n",
    "    x_test = np.load('./data/training-data/tiled_patched_images_576_576_test.npy')\n",
    "    y_train = np.load('./data/training-data/tiled_patched_masks_576_576_train.npy')\n",
    "    y_test = np.load('./data/training-data/tiled_patched_masks_576_576_test.npy')\n",
    "    \n",
    "    #train_imgs = np.load('./data/training-data/resized_data_{}x{}_imgs.npy'.format(img_w,img_h))[()]\n",
    "    #train_msks = np.load('./data/training-data/resized_data_{}x{}_msks.npy'.format(img_w,img_h))[()]\n",
    "    \n",
    "    #x = np.rollaxis(np.concatenate([i[np.newaxis,...] for i in train_imgs.values()],axis=0),3,1)\n",
    "    #y = np.rollaxis(np.concatenate([i[np.newaxis,...] for i in train_msks.values()],axis=0),3,1).astype(np.float32)\n",
    "    #y = y.reshape((y.shape[0],y.shape[1],y.shape[2]*y.shape[3]))\n",
    "    '''\n",
    "    Classes:\n",
    "    0 Buildings - large building, residential, non-residential, fuel storage facility, fortified building\n",
    "    1 Misc. Manmade structures \n",
    "    2 Road \n",
    "    3 Track - poor/dirt/cart track, footpath/trail\n",
    "    4 Trees - woodland, hedgerows, groups of trees, standalone trees\n",
    "    5 Crops - contour ploughing/cropland, grain (wheat) crops, row (potatoes, turnips) crops\n",
    "    6 Waterway \n",
    "    7 Standing water\n",
    "    8 Vehicle Large - large vehicle (e.g. lorry, truck,bus), logistics vehicle\n",
    "    9 Vehicle Small - small vehicle (car, van), motorbike\n",
    "    '''    \n",
    "    return x_train,x_test, y_train,y_test\n",
    "\n",
    "img_h,img_w = 160,160\n",
    "x_train,x_test, y_train,y_test = import_data(img_h,img_w)\n",
    "\n",
    "# Increment the counter\n",
    "def counter():\n",
    "    run = np.load('./data/misc/run_counter.npy')\n",
    "    run += 1\n",
    "    np.save('./data/misc/run_counter.npy',run)\n",
    "    return run\n",
    "run = counter()\n",
    "\n",
    "# Set the counter to a specific value\n",
    "def set_counter(run):\n",
    "    run = run\n",
    "    np.save('./data/misc/run_counter.npy',run)\n",
    "    return run\n",
    "# Uncomment the next line to manually set the counter if something goes wrong\n",
    "#run = set_counter(121)\n",
    "print('This is run # %i' %run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.52 s, sys: 22.8 ms, total: 1.54 s\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def compiler(img_rows = x_train.shape[2],img_cols = x_train.shape[3],\n",
    "            nfilters = 64,activation = 'relu',init = 'he_normal',\n",
    "            lr=0.001,decay=0.0,p=[0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2]):\n",
    "    \n",
    "    def jaccard(y_true, y_pred,smooth=1.):\n",
    "        y_true_f = K.flatten(y_true)\n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n",
    "    \n",
    "    def Conv2DReluBatchNorm(n_filter, w_filter, h_filter, inputs, activation, init='he_uniform',dropout=0.2):\n",
    "        return BatchNormalization(mode=2, axis=1)(Activation(activation=activation)((Convolution2D(n_filter, w_filter, h_filter, border_mode='same',init=init)(inputs))))\n",
    "        \n",
    "    def up_conv(nfilters,filter_factor,inputs,init=init,activation=activation):\n",
    "        return BatchNormalization(mode=2, axis=1)(Activation(activation=activation)(Convolution2D(nfilters*filter_factor, 2, 2, border_mode='same',init=init)(UpSampling2D(size=(2, 2))(inputs))))\n",
    "\n",
    "    inputs = Input((20, img_rows, img_cols))\n",
    "    \n",
    "    conv1 = Conv2DReluBatchNorm(nfilters, 3, 3, inputs, activation=activation,init=init)\n",
    "    conv1 = Conv2DReluBatchNorm(nfilters, 3, 3, conv1, activation=activation,init=init)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(p=p[0])(pool1)\n",
    "\n",
    "    conv2 = Conv2DReluBatchNorm(nfilters*2, 3, 3, pool1, activation=activation,init=init)\n",
    "    conv2 = Conv2DReluBatchNorm(nfilters*2, 3, 3, conv2, activation=activation,init=init)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(p=p[1])(pool2)\n",
    "\n",
    "    conv3 = Conv2DReluBatchNorm(nfilters*4, 3, 3, pool2, activation=activation,init=init)\n",
    "    conv3 = Conv2DReluBatchNorm(nfilters*4, 3, 3, conv3, activation=activation,init=init)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(p=p[2])(pool3)\n",
    "\n",
    "    conv4 = Conv2DReluBatchNorm(nfilters*8, 3, 3, pool3, activation=activation,init=init)\n",
    "    conv4 = Conv2DReluBatchNorm(nfilters*8, 3, 3, conv4, activation=activation,init=init)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(p=p[3])(pool4)\n",
    "\n",
    "    conv5 = Conv2DReluBatchNorm(nfilters*16, 3, 3, pool4, activation=activation,init=init)\n",
    "    conv5 = Conv2DReluBatchNorm(nfilters*16, 3, 3, conv5, activation=activation,init=init)\n",
    "    conv5 = Dropout(p=p[4])(conv5)\n",
    "        \n",
    "    up6 = merge([up_conv(nfilters,8,conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = Conv2DReluBatchNorm(nfilters*8, 3, 3, up6, activation=activation,init=init)\n",
    "    conv6 = Conv2DReluBatchNorm(nfilters*8, 3, 3, conv6, activation=activation,init=init)\n",
    "    conv6 = Dropout(p=p[5])(conv6)\n",
    "\n",
    "    up7 = merge([up_conv(nfilters,4,conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = Conv2DReluBatchNorm(nfilters*4, 3, 3, up7, activation=activation,init=init)\n",
    "    conv7 = Conv2DReluBatchNorm(nfilters*4, 3, 3, conv7, activation=activation,init=init)\n",
    "    conv7 = Dropout(p=p[6])(conv7)\n",
    "\n",
    "    up8 = merge([up_conv(nfilters,2,conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = Conv2DReluBatchNorm(nfilters*2, 3, 3, up8, activation=activation,init=init)\n",
    "    conv8 = Conv2DReluBatchNorm(nfilters*2, 3, 3, conv8, activation=activation,init=init)\n",
    "    conv8 = Dropout(p=p[7])(conv8)\n",
    "\n",
    "    up9 = merge([up_conv(nfilters,1,conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = Conv2DReluBatchNorm(nfilters, 3, 3, up9, activation=activation,init=init)\n",
    "    conv9 = Conv2DReluBatchNorm(nfilters, 3, 3, conv9, activation=activation,init=init)\n",
    "    conv9 = Dropout(p=p[8])(conv9)\n",
    "    \n",
    "    conv10 = Conv2DReluBatchNorm(1, 1, 1, conv9, activation='relu',init=init)\n",
    "    output = Activation(activation='sigmoid')(conv10)\n",
    "    \n",
    "    model = Model(input=inputs, output=output)\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=lr,decay=decay), loss='binary_crossentropy',metrics=[jaccard])\n",
    "\n",
    "    return model\n",
    "\n",
    "#p = [0]*9\n",
    "p=[0.1,0.2,0.3,0.4,0.5,0.4,0.3,0.2,0.1] # current version\n",
    "#p=[0.2,0.3,0.4,0.5,0.5,0.5,0.4,0.3,0.2] # symmetric but more dropout\n",
    "#p=[0.2,0.2,0.3,0.3,0.4,0.4,0.5,0.5,0.6] # increasing\n",
    "\n",
    "model = compiler(img_rows=x_train.shape[2],img_cols=x_train.shape[3],\n",
    "            nfilters=16,activation='relu',init='he_normal',\n",
    "            lr=0.001,p=p)\n",
    "model.save_weights('./data/misc/initial_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is run # 124 for class 4\n",
      "Train on 260 samples, validate on 64 samples\n",
      "Epoch 1/1000\n",
      "260/260 [==============================] - 22s - loss: 0.6357 - jaccard: 0.1788 - val_loss: 0.5855 - val_jaccard: 0.1798\n",
      "Epoch 2/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5583 - jaccard: 0.2025 - val_loss: 0.5543 - val_jaccard: 0.1909\n",
      "Epoch 3/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5343 - jaccard: 0.2104 - val_loss: 0.5339 - val_jaccard: 0.1976\n",
      "Epoch 4/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5158 - jaccard: 0.2162 - val_loss: 0.5220 - val_jaccard: 0.2018\n",
      "Epoch 5/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5014 - jaccard: 0.2229 - val_loss: 0.5113 - val_jaccard: 0.2058\n",
      "Epoch 6/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4939 - jaccard: 0.2252 - val_loss: 0.4990 - val_jaccard: 0.2099\n",
      "Epoch 7/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4897 - jaccard: 0.2244 - val_loss: 0.4904 - val_jaccard: 0.2119\n",
      "Epoch 8/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4770 - jaccard: 0.2286 - val_loss: 0.4772 - val_jaccard: 0.2175\n",
      "Epoch 9/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4656 - jaccard: 0.2339 - val_loss: 0.4689 - val_jaccard: 0.2205\n",
      "Epoch 10/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4600 - jaccard: 0.2370 - val_loss: 0.4635 - val_jaccard: 0.2232\n",
      "Epoch 11/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4490 - jaccard: 0.2431 - val_loss: 0.4599 - val_jaccard: 0.2235\n",
      "Epoch 12/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4460 - jaccard: 0.2424 - val_loss: 0.4516 - val_jaccard: 0.2284\n",
      "Epoch 13/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4366 - jaccard: 0.2472 - val_loss: 0.4466 - val_jaccard: 0.2302\n",
      "Epoch 14/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4320 - jaccard: 0.2494 - val_loss: 0.4410 - val_jaccard: 0.2327\n",
      "Epoch 15/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4251 - jaccard: 0.2522 - val_loss: 0.4341 - val_jaccard: 0.2344\n",
      "Epoch 16/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4213 - jaccard: 0.2525 - val_loss: 0.4268 - val_jaccard: 0.2376\n",
      "Epoch 17/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4182 - jaccard: 0.2541 - val_loss: 0.4232 - val_jaccard: 0.2401\n",
      "Epoch 18/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4082 - jaccard: 0.2601 - val_loss: 0.4232 - val_jaccard: 0.2410\n",
      "Epoch 19/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4056 - jaccard: 0.2609 - val_loss: 0.4136 - val_jaccard: 0.2439\n",
      "Epoch 20/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4040 - jaccard: 0.2604 - val_loss: 0.4110 - val_jaccard: 0.2458\n",
      "Epoch 21/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3951 - jaccard: 0.2670 - val_loss: 0.4091 - val_jaccard: 0.2459\n",
      "Epoch 22/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3949 - jaccard: 0.2635 - val_loss: 0.4023 - val_jaccard: 0.2499\n",
      "Epoch 23/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3888 - jaccard: 0.2677 - val_loss: 0.4033 - val_jaccard: 0.2539\n",
      "Epoch 24/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3855 - jaccard: 0.2705 - val_loss: 0.3910 - val_jaccard: 0.2536\n",
      "Epoch 25/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3818 - jaccard: 0.2720 - val_loss: 0.3897 - val_jaccard: 0.2551\n",
      "Epoch 26/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3760 - jaccard: 0.2748 - val_loss: 0.3920 - val_jaccard: 0.2555\n",
      "Epoch 27/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3722 - jaccard: 0.2780 - val_loss: 0.3860 - val_jaccard: 0.2572\n",
      "Epoch 28/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3684 - jaccard: 0.2811 - val_loss: 0.3766 - val_jaccard: 0.2585\n",
      "Epoch 29/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3651 - jaccard: 0.2834 - val_loss: 0.3744 - val_jaccard: 0.2608\n",
      "Epoch 30/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3632 - jaccard: 0.2814 - val_loss: 0.3802 - val_jaccard: 0.2600\n",
      "Epoch 31/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3582 - jaccard: 0.2862 - val_loss: 0.3676 - val_jaccard: 0.2654\n",
      "Epoch 32/1000\n",
      "260/260 [==============================] - 21s - loss: 0.3583 - jaccard: 0.2850 - val_loss: 0.3637 - val_jaccard: 0.2663\n",
      "Epoch 33/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3542 - jaccard: 0.2859 - val_loss: 0.3686 - val_jaccard: 0.2682\n",
      "Epoch 34/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3508 - jaccard: 0.2882 - val_loss: 0.3609 - val_jaccard: 0.2689\n",
      "Epoch 35/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3452 - jaccard: 0.2956 - val_loss: 0.3623 - val_jaccard: 0.2669\n",
      "Epoch 36/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3465 - jaccard: 0.2896 - val_loss: 0.3565 - val_jaccard: 0.2747\n",
      "Epoch 37/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3387 - jaccard: 0.2980 - val_loss: 0.3535 - val_jaccard: 0.2736\n",
      "Epoch 38/1000\n",
      "260/260 [==============================] - 21s - loss: 0.3398 - jaccard: 0.2952 - val_loss: 0.3539 - val_jaccard: 0.2747\n",
      "Epoch 39/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3361 - jaccard: 0.2974 - val_loss: 0.3458 - val_jaccard: 0.2785\n",
      "Epoch 40/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3317 - jaccard: 0.3008 - val_loss: 0.3421 - val_jaccard: 0.2806\n",
      "Epoch 41/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3351 - jaccard: 0.2959 - val_loss: 0.3431 - val_jaccard: 0.2804\n",
      "Epoch 42/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3277 - jaccard: 0.3040 - val_loss: 0.3370 - val_jaccard: 0.2828\n",
      "Epoch 43/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3251 - jaccard: 0.3036 - val_loss: 0.3438 - val_jaccard: 0.2834\n",
      "Epoch 44/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3230 - jaccard: 0.3088 - val_loss: 0.3347 - val_jaccard: 0.2824\n",
      "Epoch 45/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3212 - jaccard: 0.3061 - val_loss: 0.3329 - val_jaccard: 0.2828\n",
      "Epoch 46/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3197 - jaccard: 0.3090 - val_loss: 0.3312 - val_jaccard: 0.2853\n",
      "Epoch 47/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3122 - jaccard: 0.3125 - val_loss: 0.3451 - val_jaccard: 0.2836\n",
      "Epoch 48/1000\n",
      "260/260 [==============================] - 21s - loss: 0.3125 - jaccard: 0.3144 - val_loss: 0.3250 - val_jaccard: 0.2877\n",
      "Epoch 49/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3108 - jaccard: 0.3138 - val_loss: 0.3384 - val_jaccard: 0.2881\n",
      "Epoch 50/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3071 - jaccard: 0.3183 - val_loss: 0.3264 - val_jaccard: 0.2929\n",
      "Epoch 51/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3068 - jaccard: 0.3170 - val_loss: 0.3248 - val_jaccard: 0.2939\n",
      "Epoch 52/1000\n",
      "260/260 [==============================] - 22s - loss: 0.3040 - jaccard: 0.3195 - val_loss: 0.3247 - val_jaccard: 0.2954\n",
      "Epoch 53/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2986 - jaccard: 0.3245 - val_loss: 0.3156 - val_jaccard: 0.2929\n",
      "Epoch 54/1000\n",
      "260/260 [==============================] - 21s - loss: 0.3054 - jaccard: 0.3180 - val_loss: 0.3159 - val_jaccard: 0.2900\n",
      "Epoch 55/1000\n",
      "260/260 [==============================] - 21s - loss: 0.3025 - jaccard: 0.3210 - val_loss: 0.3238 - val_jaccard: 0.2939\n",
      "Epoch 56/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2944 - jaccard: 0.3272 - val_loss: 0.3127 - val_jaccard: 0.2992\n",
      "Epoch 57/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2923 - jaccard: 0.3297 - val_loss: 0.3080 - val_jaccard: 0.3035\n",
      "Epoch 58/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2911 - jaccard: 0.3292 - val_loss: 0.3070 - val_jaccard: 0.3036\n",
      "Epoch 59/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2888 - jaccard: 0.3304 - val_loss: 0.3156 - val_jaccard: 0.3034\n",
      "Epoch 60/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2842 - jaccard: 0.3363 - val_loss: 0.3121 - val_jaccard: 0.3025\n",
      "Epoch 61/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2846 - jaccard: 0.3359 - val_loss: 0.3075 - val_jaccard: 0.3053\n",
      "Epoch 62/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2817 - jaccard: 0.3373 - val_loss: 0.3066 - val_jaccard: 0.3060\n",
      "Epoch 63/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2806 - jaccard: 0.3379 - val_loss: 0.3135 - val_jaccard: 0.3052\n",
      "Epoch 64/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2791 - jaccard: 0.3404 - val_loss: 0.3064 - val_jaccard: 0.3100\n",
      "Epoch 65/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2768 - jaccard: 0.3410 - val_loss: 0.2962 - val_jaccard: 0.3095\n",
      "Epoch 66/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2742 - jaccard: 0.3448 - val_loss: 0.2956 - val_jaccard: 0.3144\n",
      "Epoch 67/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2758 - jaccard: 0.3403 - val_loss: 0.2942 - val_jaccard: 0.3136\n",
      "Epoch 68/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2701 - jaccard: 0.3471 - val_loss: 0.3052 - val_jaccard: 0.3153\n",
      "Epoch 69/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2690 - jaccard: 0.3485 - val_loss: 0.2942 - val_jaccard: 0.3179\n",
      "Epoch 70/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2702 - jaccard: 0.3469 - val_loss: 0.2896 - val_jaccard: 0.3146\n",
      "Epoch 71/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2672 - jaccard: 0.3498 - val_loss: 0.2861 - val_jaccard: 0.3216\n",
      "Epoch 72/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2645 - jaccard: 0.3542 - val_loss: 0.2819 - val_jaccard: 0.3229\n",
      "Epoch 73/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2636 - jaccard: 0.3552 - val_loss: 0.2833 - val_jaccard: 0.3203\n",
      "Epoch 74/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2694 - jaccard: 0.3442 - val_loss: 0.2809 - val_jaccard: 0.3242\n",
      "Epoch 75/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2612 - jaccard: 0.3561 - val_loss: 0.2887 - val_jaccard: 0.3233\n",
      "Epoch 76/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2584 - jaccard: 0.3594 - val_loss: 0.2879 - val_jaccard: 0.3254\n",
      "Epoch 77/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2550 - jaccard: 0.3604 - val_loss: 0.2892 - val_jaccard: 0.3288\n",
      "Epoch 78/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2561 - jaccard: 0.3619 - val_loss: 0.2823 - val_jaccard: 0.3253\n",
      "Epoch 79/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2606 - jaccard: 0.3550 - val_loss: 0.2720 - val_jaccard: 0.3294\n",
      "Epoch 80/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2508 - jaccard: 0.3691 - val_loss: 0.2791 - val_jaccard: 0.3271\n",
      "Epoch 81/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2488 - jaccard: 0.3688 - val_loss: 0.2745 - val_jaccard: 0.3333\n",
      "Epoch 82/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2508 - jaccard: 0.3659 - val_loss: 0.2776 - val_jaccard: 0.3343\n",
      "Epoch 83/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2459 - jaccard: 0.3755 - val_loss: 0.2676 - val_jaccard: 0.3326\n",
      "Epoch 84/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2455 - jaccard: 0.3696 - val_loss: 0.2787 - val_jaccard: 0.3375\n",
      "Epoch 85/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2435 - jaccard: 0.3765 - val_loss: 0.2752 - val_jaccard: 0.3370\n",
      "Epoch 86/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2423 - jaccard: 0.3758 - val_loss: 0.2715 - val_jaccard: 0.3364\n",
      "Epoch 87/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2404 - jaccard: 0.3790 - val_loss: 0.2610 - val_jaccard: 0.3433\n",
      "Epoch 88/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2446 - jaccard: 0.3718 - val_loss: 0.2646 - val_jaccard: 0.3344\n",
      "Epoch 89/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2378 - jaccard: 0.3791 - val_loss: 0.2779 - val_jaccard: 0.3400\n",
      "Epoch 90/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2443 - jaccard: 0.3730 - val_loss: 0.2624 - val_jaccard: 0.3322\n",
      "Epoch 91/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2427 - jaccard: 0.3738 - val_loss: 0.2655 - val_jaccard: 0.3393\n",
      "Epoch 92/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2431 - jaccard: 0.3741 - val_loss: 0.2659 - val_jaccard: 0.3427\n",
      "Epoch 93/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2374 - jaccard: 0.3828 - val_loss: 0.2664 - val_jaccard: 0.3450\n",
      "Epoch 94/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2321 - jaccard: 0.3877 - val_loss: 0.2648 - val_jaccard: 0.3502\n",
      "Epoch 95/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2325 - jaccard: 0.3868 - val_loss: 0.2620 - val_jaccard: 0.3489\n",
      "Epoch 96/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2327 - jaccard: 0.3875 - val_loss: 0.2737 - val_jaccard: 0.3429\n",
      "Epoch 97/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2296 - jaccard: 0.3889 - val_loss: 0.2614 - val_jaccard: 0.3530\n",
      "Epoch 98/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2314 - jaccard: 0.3879 - val_loss: 0.2765 - val_jaccard: 0.3461\n",
      "Epoch 99/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2313 - jaccard: 0.3874 - val_loss: 0.2692 - val_jaccard: 0.3477\n",
      "Epoch 100/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2278 - jaccard: 0.3929 - val_loss: 0.2695 - val_jaccard: 0.3535\n",
      "Epoch 101/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2226 - jaccard: 0.3992 - val_loss: 0.2592 - val_jaccard: 0.3539\n",
      "Epoch 102/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2211 - jaccard: 0.4000 - val_loss: 0.2594 - val_jaccard: 0.3578\n",
      "Epoch 103/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2195 - jaccard: 0.4054 - val_loss: 0.2533 - val_jaccard: 0.3608\n",
      "Epoch 104/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2208 - jaccard: 0.4041 - val_loss: 0.2559 - val_jaccard: 0.3514\n",
      "Epoch 105/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2215 - jaccard: 0.4000 - val_loss: 0.2485 - val_jaccard: 0.3574\n",
      "Epoch 106/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2214 - jaccard: 0.3982 - val_loss: 0.2584 - val_jaccard: 0.3663\n",
      "Epoch 107/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2166 - jaccard: 0.4119 - val_loss: 0.2534 - val_jaccard: 0.3540\n",
      "Epoch 108/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2151 - jaccard: 0.4091 - val_loss: 0.2475 - val_jaccard: 0.3624\n",
      "Epoch 109/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2152 - jaccard: 0.4079 - val_loss: 0.2491 - val_jaccard: 0.3661\n",
      "Epoch 110/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2168 - jaccard: 0.4042 - val_loss: 0.2568 - val_jaccard: 0.3663\n",
      "Epoch 111/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2116 - jaccard: 0.4146 - val_loss: 0.2533 - val_jaccard: 0.3659\n",
      "Epoch 112/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2143 - jaccard: 0.4120 - val_loss: 0.2515 - val_jaccard: 0.3636\n",
      "Epoch 113/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2150 - jaccard: 0.4096 - val_loss: 0.2557 - val_jaccard: 0.3593\n",
      "Epoch 114/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2100 - jaccard: 0.4157 - val_loss: 0.2558 - val_jaccard: 0.3688\n",
      "Epoch 115/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2100 - jaccard: 0.4173 - val_loss: 0.2544 - val_jaccard: 0.3722\n",
      "Epoch 116/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2094 - jaccard: 0.4190 - val_loss: 0.2510 - val_jaccard: 0.3688\n",
      "Epoch 117/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2075 - jaccard: 0.4181 - val_loss: 0.2512 - val_jaccard: 0.3745\n",
      "Epoch 118/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2084 - jaccard: 0.4204 - val_loss: 0.2458 - val_jaccard: 0.3743\n",
      "Epoch 119/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2109 - jaccard: 0.4161 - val_loss: 0.2479 - val_jaccard: 0.3739\n",
      "Epoch 120/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2047 - jaccard: 0.4258 - val_loss: 0.2389 - val_jaccard: 0.3776\n",
      "Epoch 121/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2039 - jaccard: 0.4295 - val_loss: 0.2355 - val_jaccard: 0.3684\n",
      "Epoch 122/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2070 - jaccard: 0.4182 - val_loss: 0.2464 - val_jaccard: 0.3726\n",
      "Epoch 123/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2031 - jaccard: 0.4271 - val_loss: 0.2363 - val_jaccard: 0.3715\n",
      "Epoch 124/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2029 - jaccard: 0.4260 - val_loss: 0.2483 - val_jaccard: 0.3724\n",
      "Epoch 125/1000\n",
      "260/260 [==============================] - 22s - loss: 0.2013 - jaccard: 0.4278 - val_loss: 0.2365 - val_jaccard: 0.3829\n",
      "Epoch 126/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1967 - jaccard: 0.4389 - val_loss: 0.2413 - val_jaccard: 0.3845\n",
      "Epoch 127/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1980 - jaccard: 0.4381 - val_loss: 0.2496 - val_jaccard: 0.3734\n",
      "Epoch 128/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1983 - jaccard: 0.4330 - val_loss: 0.2397 - val_jaccard: 0.3770\n",
      "Epoch 129/1000\n",
      "260/260 [==============================] - 21s - loss: 0.2002 - jaccard: 0.4308 - val_loss: 0.2532 - val_jaccard: 0.3756\n",
      "Epoch 130/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1960 - jaccard: 0.4374 - val_loss: 0.2489 - val_jaccard: 0.3770\n",
      "Epoch 131/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1969 - jaccard: 0.4332 - val_loss: 0.2454 - val_jaccard: 0.3804\n",
      "Epoch 132/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1954 - jaccard: 0.4379 - val_loss: 0.2580 - val_jaccard: 0.3781\n",
      "Epoch 133/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1957 - jaccard: 0.4363 - val_loss: 0.2451 - val_jaccard: 0.3880\n",
      "Epoch 134/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1955 - jaccard: 0.4395 - val_loss: 0.2449 - val_jaccard: 0.3880\n",
      "Epoch 135/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1936 - jaccard: 0.4387 - val_loss: 0.2346 - val_jaccard: 0.3821\n",
      "Epoch 136/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1927 - jaccard: 0.4439 - val_loss: 0.2380 - val_jaccard: 0.3837\n",
      "Epoch 137/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1902 - jaccard: 0.4482 - val_loss: 0.2495 - val_jaccard: 0.3804\n",
      "Epoch 138/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1931 - jaccard: 0.4393 - val_loss: 0.2427 - val_jaccard: 0.3968\n",
      "Epoch 139/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1899 - jaccard: 0.4525 - val_loss: 0.2528 - val_jaccard: 0.3801\n",
      "Epoch 140/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1894 - jaccard: 0.4478 - val_loss: 0.2406 - val_jaccard: 0.3920\n",
      "Epoch 141/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1944 - jaccard: 0.4400 - val_loss: 0.2474 - val_jaccard: 0.3877\n",
      "Epoch 142/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1903 - jaccard: 0.4451 - val_loss: 0.2284 - val_jaccard: 0.3968\n",
      "Epoch 143/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1871 - jaccard: 0.4535 - val_loss: 0.2371 - val_jaccard: 0.3889\n",
      "Epoch 144/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1852 - jaccard: 0.4555 - val_loss: 0.2517 - val_jaccard: 0.3911\n",
      "Epoch 145/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1876 - jaccard: 0.4522 - val_loss: 0.2330 - val_jaccard: 0.3944\n",
      "Epoch 146/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1860 - jaccard: 0.4528 - val_loss: 0.2417 - val_jaccard: 0.3956\n",
      "Epoch 147/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1883 - jaccard: 0.4481 - val_loss: 0.2322 - val_jaccard: 0.4001\n",
      "Epoch 148/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1835 - jaccard: 0.4578 - val_loss: 0.2356 - val_jaccard: 0.3993\n",
      "Epoch 149/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1834 - jaccard: 0.4597 - val_loss: 0.2357 - val_jaccard: 0.4035\n",
      "Epoch 150/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1834 - jaccard: 0.4601 - val_loss: 0.2443 - val_jaccard: 0.3900\n",
      "Epoch 151/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1831 - jaccard: 0.4610 - val_loss: 0.2279 - val_jaccard: 0.3863\n",
      "Epoch 152/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1827 - jaccard: 0.4563 - val_loss: 0.2310 - val_jaccard: 0.4029\n",
      "Epoch 153/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1791 - jaccard: 0.4672 - val_loss: 0.2351 - val_jaccard: 0.3996\n",
      "Epoch 154/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1797 - jaccard: 0.4674 - val_loss: 0.2349 - val_jaccard: 0.4049\n",
      "Epoch 155/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1794 - jaccard: 0.4637 - val_loss: 0.2509 - val_jaccard: 0.3954\n",
      "Epoch 156/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1853 - jaccard: 0.4583 - val_loss: 0.2233 - val_jaccard: 0.4035\n",
      "Epoch 157/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1790 - jaccard: 0.4658 - val_loss: 0.2298 - val_jaccard: 0.4028\n",
      "Epoch 158/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1772 - jaccard: 0.4683 - val_loss: 0.2262 - val_jaccard: 0.4078\n",
      "Epoch 159/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1792 - jaccard: 0.4655 - val_loss: 0.2287 - val_jaccard: 0.4009\n",
      "Epoch 160/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1757 - jaccard: 0.4725 - val_loss: 0.2326 - val_jaccard: 0.4006\n",
      "Epoch 161/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1770 - jaccard: 0.4720 - val_loss: 0.2268 - val_jaccard: 0.4055\n",
      "Epoch 162/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1748 - jaccard: 0.4770 - val_loss: 0.2370 - val_jaccard: 0.4032\n",
      "Epoch 163/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1717 - jaccard: 0.4802 - val_loss: 0.2454 - val_jaccard: 0.3996\n",
      "Epoch 164/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1737 - jaccard: 0.4751 - val_loss: 0.2238 - val_jaccard: 0.4118\n",
      "Epoch 165/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1764 - jaccard: 0.4730 - val_loss: 0.2262 - val_jaccard: 0.4058\n",
      "Epoch 166/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1715 - jaccard: 0.4808 - val_loss: 0.2370 - val_jaccard: 0.4062\n",
      "Epoch 167/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1711 - jaccard: 0.4821 - val_loss: 0.2402 - val_jaccard: 0.4071\n",
      "Epoch 168/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1725 - jaccard: 0.4787 - val_loss: 0.2281 - val_jaccard: 0.4136\n",
      "Epoch 169/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1715 - jaccard: 0.4772 - val_loss: 0.2401 - val_jaccard: 0.4074\n",
      "Epoch 170/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1724 - jaccard: 0.4794 - val_loss: 0.2331 - val_jaccard: 0.4156\n",
      "Epoch 171/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1678 - jaccard: 0.4861 - val_loss: 0.2353 - val_jaccard: 0.4158\n",
      "Epoch 172/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1749 - jaccard: 0.4740 - val_loss: 0.2191 - val_jaccard: 0.4186\n",
      "Epoch 173/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1739 - jaccard: 0.4749 - val_loss: 0.2319 - val_jaccard: 0.4120\n",
      "Epoch 174/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1709 - jaccard: 0.4803 - val_loss: 0.2248 - val_jaccard: 0.4157\n",
      "Epoch 175/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1659 - jaccard: 0.4916 - val_loss: 0.2302 - val_jaccard: 0.4135\n",
      "Epoch 176/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1658 - jaccard: 0.4910 - val_loss: 0.2395 - val_jaccard: 0.4158\n",
      "Epoch 177/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1658 - jaccard: 0.4924 - val_loss: 0.2262 - val_jaccard: 0.4162\n",
      "Epoch 178/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1660 - jaccard: 0.4913 - val_loss: 0.2218 - val_jaccard: 0.4231\n",
      "Epoch 179/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1649 - jaccard: 0.4961 - val_loss: 0.2193 - val_jaccard: 0.4185\n",
      "Epoch 180/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1659 - jaccard: 0.4878 - val_loss: 0.2280 - val_jaccard: 0.4167\n",
      "Epoch 181/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1647 - jaccard: 0.4950 - val_loss: 0.2274 - val_jaccard: 0.4186\n",
      "Epoch 182/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1645 - jaccard: 0.4953 - val_loss: 0.2394 - val_jaccard: 0.4140\n",
      "Epoch 183/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1615 - jaccard: 0.5017 - val_loss: 0.2261 - val_jaccard: 0.4219\n",
      "Epoch 184/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1635 - jaccard: 0.4952 - val_loss: 0.2369 - val_jaccard: 0.4200\n",
      "Epoch 185/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1640 - jaccard: 0.4957 - val_loss: 0.2276 - val_jaccard: 0.4218\n",
      "Epoch 186/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1612 - jaccard: 0.5011 - val_loss: 0.2247 - val_jaccard: 0.4199\n",
      "Epoch 187/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1639 - jaccard: 0.4978 - val_loss: 0.2275 - val_jaccard: 0.4265\n",
      "Epoch 188/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1638 - jaccard: 0.4944 - val_loss: 0.2409 - val_jaccard: 0.4140\n",
      "Epoch 189/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1622 - jaccard: 0.4968 - val_loss: 0.2217 - val_jaccard: 0.4262\n",
      "Epoch 190/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1638 - jaccard: 0.4948 - val_loss: 0.2267 - val_jaccard: 0.4172\n",
      "Epoch 191/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1595 - jaccard: 0.5050 - val_loss: 0.2312 - val_jaccard: 0.4171\n",
      "Epoch 192/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1607 - jaccard: 0.5028 - val_loss: 0.2249 - val_jaccard: 0.4314\n",
      "Epoch 193/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1590 - jaccard: 0.5038 - val_loss: 0.2287 - val_jaccard: 0.4246\n",
      "Epoch 194/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1579 - jaccard: 0.5080 - val_loss: 0.2266 - val_jaccard: 0.4306\n",
      "Epoch 195/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1578 - jaccard: 0.5094 - val_loss: 0.2270 - val_jaccard: 0.4225\n",
      "Epoch 196/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1597 - jaccard: 0.5061 - val_loss: 0.2204 - val_jaccard: 0.4184\n",
      "Epoch 197/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1597 - jaccard: 0.5032 - val_loss: 0.2377 - val_jaccard: 0.4299\n",
      "Epoch 198/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1578 - jaccard: 0.5074 - val_loss: 0.2249 - val_jaccard: 0.4325\n",
      "Epoch 199/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1579 - jaccard: 0.5066 - val_loss: 0.2355 - val_jaccard: 0.4296\n",
      "Epoch 200/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1563 - jaccard: 0.5075 - val_loss: 0.2216 - val_jaccard: 0.4351\n",
      "Epoch 201/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1547 - jaccard: 0.5173 - val_loss: 0.2383 - val_jaccard: 0.4258\n",
      "Epoch 202/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1553 - jaccard: 0.5158 - val_loss: 0.2214 - val_jaccard: 0.4283\n",
      "Epoch 203/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1557 - jaccard: 0.5109 - val_loss: 0.2279 - val_jaccard: 0.4322\n",
      "Epoch 204/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1532 - jaccard: 0.5194 - val_loss: 0.2176 - val_jaccard: 0.4360\n",
      "Epoch 205/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1536 - jaccard: 0.5148 - val_loss: 0.2281 - val_jaccard: 0.4314\n",
      "Epoch 206/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1532 - jaccard: 0.5187 - val_loss: 0.2266 - val_jaccard: 0.4285\n",
      "Epoch 207/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1565 - jaccard: 0.5116 - val_loss: 0.2173 - val_jaccard: 0.4335\n",
      "Epoch 208/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1570 - jaccard: 0.5092 - val_loss: 0.2231 - val_jaccard: 0.4300\n",
      "Epoch 209/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1558 - jaccard: 0.5155 - val_loss: 0.2335 - val_jaccard: 0.4300\n",
      "Epoch 210/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1537 - jaccard: 0.5154 - val_loss: 0.2154 - val_jaccard: 0.4359\n",
      "Epoch 211/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1558 - jaccard: 0.5128 - val_loss: 0.2148 - val_jaccard: 0.4295\n",
      "Epoch 212/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1527 - jaccard: 0.5158 - val_loss: 0.2275 - val_jaccard: 0.4278\n",
      "Epoch 213/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1509 - jaccard: 0.5243 - val_loss: 0.2152 - val_jaccard: 0.4406\n",
      "Epoch 214/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1554 - jaccard: 0.5168 - val_loss: 0.2414 - val_jaccard: 0.4257\n",
      "Epoch 215/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1591 - jaccard: 0.5074 - val_loss: 0.2115 - val_jaccard: 0.4294\n",
      "Epoch 216/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1510 - jaccard: 0.5247 - val_loss: 0.2065 - val_jaccard: 0.4495\n",
      "Epoch 217/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1534 - jaccard: 0.5203 - val_loss: 0.2070 - val_jaccard: 0.4390\n",
      "Epoch 218/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1511 - jaccard: 0.5212 - val_loss: 0.2170 - val_jaccard: 0.4456\n",
      "Epoch 219/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1481 - jaccard: 0.5313 - val_loss: 0.2112 - val_jaccard: 0.4483\n",
      "Epoch 220/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1464 - jaccard: 0.5342 - val_loss: 0.2132 - val_jaccard: 0.4452\n",
      "Epoch 221/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1462 - jaccard: 0.5361 - val_loss: 0.2211 - val_jaccard: 0.4421\n",
      "Epoch 222/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1486 - jaccard: 0.5292 - val_loss: 0.2111 - val_jaccard: 0.4376\n",
      "Epoch 223/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1464 - jaccard: 0.5360 - val_loss: 0.2156 - val_jaccard: 0.4414\n",
      "Epoch 224/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1467 - jaccard: 0.5274 - val_loss: 0.2156 - val_jaccard: 0.4389\n",
      "Epoch 225/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1496 - jaccard: 0.5251 - val_loss: 0.2059 - val_jaccard: 0.4413\n",
      "Epoch 226/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1483 - jaccard: 0.5304 - val_loss: 0.2174 - val_jaccard: 0.4369\n",
      "Epoch 227/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1478 - jaccard: 0.5322 - val_loss: 0.2285 - val_jaccard: 0.4393\n",
      "Epoch 228/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1463 - jaccard: 0.5304 - val_loss: 0.2147 - val_jaccard: 0.4462\n",
      "Epoch 229/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1446 - jaccard: 0.5385 - val_loss: 0.2125 - val_jaccard: 0.4443\n",
      "Epoch 230/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1468 - jaccard: 0.5328 - val_loss: 0.2199 - val_jaccard: 0.4501\n",
      "Epoch 231/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1465 - jaccard: 0.5355 - val_loss: 0.2216 - val_jaccard: 0.4480\n",
      "Epoch 232/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1476 - jaccard: 0.5317 - val_loss: 0.2145 - val_jaccard: 0.4432\n",
      "Epoch 233/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1462 - jaccard: 0.5347 - val_loss: 0.2137 - val_jaccard: 0.4485\n",
      "Epoch 234/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1457 - jaccard: 0.5347 - val_loss: 0.2169 - val_jaccard: 0.4377\n",
      "Epoch 235/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1457 - jaccard: 0.5336 - val_loss: 0.2229 - val_jaccard: 0.4453\n",
      "Epoch 236/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1431 - jaccard: 0.5412 - val_loss: 0.2194 - val_jaccard: 0.4428\n",
      "Epoch 237/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1462 - jaccard: 0.5328 - val_loss: 0.2318 - val_jaccard: 0.4416\n",
      "Epoch 238/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1437 - jaccard: 0.5395 - val_loss: 0.2219 - val_jaccard: 0.4409\n",
      "Epoch 239/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1410 - jaccard: 0.5482 - val_loss: 0.2231 - val_jaccard: 0.4455\n",
      "Epoch 240/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1414 - jaccard: 0.5455 - val_loss: 0.2142 - val_jaccard: 0.4535\n",
      "Epoch 241/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1424 - jaccard: 0.5425 - val_loss: 0.2176 - val_jaccard: 0.4520\n",
      "Epoch 242/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1444 - jaccard: 0.5388 - val_loss: 0.2171 - val_jaccard: 0.4547\n",
      "Epoch 243/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1417 - jaccard: 0.5447 - val_loss: 0.2142 - val_jaccard: 0.4504\n",
      "Epoch 244/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1461 - jaccard: 0.5363 - val_loss: 0.2232 - val_jaccard: 0.4342\n",
      "Epoch 245/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1441 - jaccard: 0.5373 - val_loss: 0.2205 - val_jaccard: 0.4411\n",
      "Epoch 246/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1404 - jaccard: 0.5490 - val_loss: 0.2264 - val_jaccard: 0.4510\n",
      "Epoch 247/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1441 - jaccard: 0.5417 - val_loss: 0.2193 - val_jaccard: 0.4416\n",
      "Epoch 248/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1477 - jaccard: 0.5375 - val_loss: 0.2250 - val_jaccard: 0.4384\n",
      "Epoch 249/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1443 - jaccard: 0.5387 - val_loss: 0.2268 - val_jaccard: 0.4477\n",
      "Epoch 250/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1393 - jaccard: 0.5517 - val_loss: 0.2220 - val_jaccard: 0.4475\n",
      "Epoch 251/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1381 - jaccard: 0.5526 - val_loss: 0.2124 - val_jaccard: 0.4581\n",
      "Epoch 252/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1390 - jaccard: 0.5512 - val_loss: 0.2154 - val_jaccard: 0.4531\n",
      "Epoch 253/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1384 - jaccard: 0.5535 - val_loss: 0.2159 - val_jaccard: 0.4492\n",
      "Epoch 254/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1387 - jaccard: 0.5526 - val_loss: 0.2186 - val_jaccard: 0.4488\n",
      "Epoch 255/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1365 - jaccard: 0.5529 - val_loss: 0.2137 - val_jaccard: 0.4542\n",
      "Epoch 256/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1368 - jaccard: 0.5578 - val_loss: 0.2338 - val_jaccard: 0.4493\n",
      "Epoch 257/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1388 - jaccard: 0.5512 - val_loss: 0.2240 - val_jaccard: 0.4430\n",
      "Epoch 258/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1359 - jaccard: 0.5619 - val_loss: 0.2186 - val_jaccard: 0.4532\n",
      "Epoch 259/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1367 - jaccard: 0.5598 - val_loss: 0.2148 - val_jaccard: 0.4559\n",
      "Epoch 260/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1390 - jaccard: 0.5528 - val_loss: 0.2237 - val_jaccard: 0.4568\n",
      "Epoch 261/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1367 - jaccard: 0.5618 - val_loss: 0.2177 - val_jaccard: 0.4512\n",
      "Epoch 262/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1336 - jaccard: 0.5657 - val_loss: 0.2253 - val_jaccard: 0.4508\n",
      "Epoch 263/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1364 - jaccard: 0.5563 - val_loss: 0.2126 - val_jaccard: 0.4512\n",
      "Epoch 264/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1370 - jaccard: 0.5587 - val_loss: 0.2154 - val_jaccard: 0.4553\n",
      "Epoch 265/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1368 - jaccard: 0.5595 - val_loss: 0.2166 - val_jaccard: 0.4581\n",
      "Epoch 266/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1345 - jaccard: 0.5616 - val_loss: 0.2245 - val_jaccard: 0.4542\n",
      "Epoch 267/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1344 - jaccard: 0.5651 - val_loss: 0.2054 - val_jaccard: 0.4612\n",
      "Epoch 268/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1350 - jaccard: 0.5640 - val_loss: 0.2122 - val_jaccard: 0.4582\n",
      "Epoch 269/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1336 - jaccard: 0.5670 - val_loss: 0.2166 - val_jaccard: 0.4570\n",
      "Epoch 270/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1327 - jaccard: 0.5690 - val_loss: 0.2212 - val_jaccard: 0.4588\n",
      "Epoch 271/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1361 - jaccard: 0.5566 - val_loss: 0.2245 - val_jaccard: 0.4602\n",
      "Epoch 272/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1331 - jaccard: 0.5674 - val_loss: 0.2252 - val_jaccard: 0.4624\n",
      "Epoch 273/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1331 - jaccard: 0.5698 - val_loss: 0.2181 - val_jaccard: 0.4637\n",
      "Epoch 274/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1351 - jaccard: 0.5631 - val_loss: 0.2232 - val_jaccard: 0.4633\n",
      "Epoch 275/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1341 - jaccard: 0.5695 - val_loss: 0.2160 - val_jaccard: 0.4585\n",
      "Epoch 276/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1323 - jaccard: 0.5698 - val_loss: 0.2157 - val_jaccard: 0.4565\n",
      "Epoch 277/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1318 - jaccard: 0.5694 - val_loss: 0.2288 - val_jaccard: 0.4518\n",
      "Epoch 278/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1342 - jaccard: 0.5661 - val_loss: 0.2220 - val_jaccard: 0.4630\n",
      "Epoch 279/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1335 - jaccard: 0.5671 - val_loss: 0.2150 - val_jaccard: 0.4621\n",
      "Epoch 280/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1326 - jaccard: 0.5690 - val_loss: 0.2123 - val_jaccard: 0.4570\n",
      "Epoch 281/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1301 - jaccard: 0.5774 - val_loss: 0.2183 - val_jaccard: 0.4549\n",
      "Epoch 282/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1314 - jaccard: 0.5739 - val_loss: 0.2170 - val_jaccard: 0.4603\n",
      "Epoch 283/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1356 - jaccard: 0.5645 - val_loss: 0.2265 - val_jaccard: 0.4564\n",
      "Epoch 284/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1311 - jaccard: 0.5718 - val_loss: 0.2095 - val_jaccard: 0.4641\n",
      "Epoch 285/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1315 - jaccard: 0.5689 - val_loss: 0.2326 - val_jaccard: 0.4592\n",
      "Epoch 286/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1305 - jaccard: 0.5741 - val_loss: 0.2167 - val_jaccard: 0.4641\n",
      "Epoch 287/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1298 - jaccard: 0.5746 - val_loss: 0.2183 - val_jaccard: 0.4596\n",
      "Epoch 288/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1312 - jaccard: 0.5727 - val_loss: 0.2128 - val_jaccard: 0.4594\n",
      "Epoch 289/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1292 - jaccard: 0.5763 - val_loss: 0.2106 - val_jaccard: 0.4669\n",
      "Epoch 290/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1314 - jaccard: 0.5722 - val_loss: 0.2251 - val_jaccard: 0.4626\n",
      "Epoch 291/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1308 - jaccard: 0.5738 - val_loss: 0.2103 - val_jaccard: 0.4618\n",
      "Epoch 292/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1283 - jaccard: 0.5800 - val_loss: 0.2149 - val_jaccard: 0.4674\n",
      "Epoch 293/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1310 - jaccard: 0.5745 - val_loss: 0.2109 - val_jaccard: 0.4702\n",
      "Epoch 294/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1282 - jaccard: 0.5764 - val_loss: 0.2236 - val_jaccard: 0.4625\n",
      "Epoch 295/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1311 - jaccard: 0.5738 - val_loss: 0.2205 - val_jaccard: 0.4652\n",
      "Epoch 296/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1322 - jaccard: 0.5761 - val_loss: 0.2181 - val_jaccard: 0.4617\n",
      "Epoch 297/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1297 - jaccard: 0.5754 - val_loss: 0.2286 - val_jaccard: 0.4671\n",
      "Epoch 298/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1270 - jaccard: 0.5823 - val_loss: 0.2208 - val_jaccard: 0.4608\n",
      "Epoch 299/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1293 - jaccard: 0.5821 - val_loss: 0.2334 - val_jaccard: 0.4553\n",
      "Epoch 300/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1295 - jaccard: 0.5761 - val_loss: 0.2438 - val_jaccard: 0.4474\n",
      "Epoch 301/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1288 - jaccard: 0.5795 - val_loss: 0.2261 - val_jaccard: 0.4668\n",
      "Epoch 302/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1259 - jaccard: 0.5860 - val_loss: 0.2375 - val_jaccard: 0.4621\n",
      "Epoch 303/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1304 - jaccard: 0.5763 - val_loss: 0.2397 - val_jaccard: 0.4549\n",
      "Epoch 304/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1274 - jaccard: 0.5790 - val_loss: 0.2244 - val_jaccard: 0.4691\n",
      "Epoch 305/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1266 - jaccard: 0.5843 - val_loss: 0.2242 - val_jaccard: 0.4626\n",
      "Epoch 306/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1261 - jaccard: 0.5874 - val_loss: 0.2168 - val_jaccard: 0.4712\n",
      "Epoch 307/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1246 - jaccard: 0.5883 - val_loss: 0.2242 - val_jaccard: 0.4690\n",
      "Epoch 308/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1235 - jaccard: 0.5939 - val_loss: 0.2245 - val_jaccard: 0.4648\n",
      "Epoch 309/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1266 - jaccard: 0.5799 - val_loss: 0.2185 - val_jaccard: 0.4715\n",
      "Epoch 310/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1272 - jaccard: 0.5811 - val_loss: 0.2332 - val_jaccard: 0.4620\n",
      "Epoch 311/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1273 - jaccard: 0.5800 - val_loss: 0.2184 - val_jaccard: 0.4697\n",
      "Epoch 312/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1251 - jaccard: 0.5886 - val_loss: 0.2210 - val_jaccard: 0.4660\n",
      "Epoch 313/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1246 - jaccard: 0.5893 - val_loss: 0.2295 - val_jaccard: 0.4636\n",
      "Epoch 314/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1255 - jaccard: 0.5876 - val_loss: 0.2267 - val_jaccard: 0.4695\n",
      "Epoch 315/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1272 - jaccard: 0.5840 - val_loss: 0.2292 - val_jaccard: 0.4607\n",
      "Epoch 316/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1265 - jaccard: 0.5822 - val_loss: 0.2296 - val_jaccard: 0.4636\n",
      "Epoch 317/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1227 - jaccard: 0.5941 - val_loss: 0.2280 - val_jaccard: 0.4661\n",
      "Epoch 318/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1236 - jaccard: 0.5928 - val_loss: 0.2254 - val_jaccard: 0.4675\n",
      "Epoch 319/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1245 - jaccard: 0.5888 - val_loss: 0.2209 - val_jaccard: 0.4634\n",
      "Epoch 320/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1263 - jaccard: 0.5867 - val_loss: 0.2205 - val_jaccard: 0.4669\n",
      "Epoch 321/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1253 - jaccard: 0.5868 - val_loss: 0.2277 - val_jaccard: 0.4658\n",
      "Epoch 322/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1239 - jaccard: 0.5912 - val_loss: 0.2181 - val_jaccard: 0.4657\n",
      "Epoch 323/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1232 - jaccard: 0.5938 - val_loss: 0.2253 - val_jaccard: 0.4706\n",
      "Epoch 324/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1231 - jaccard: 0.5928 - val_loss: 0.2340 - val_jaccard: 0.4689\n",
      "Epoch 325/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1273 - jaccard: 0.5854 - val_loss: 0.2259 - val_jaccard: 0.4698\n",
      "Epoch 326/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1260 - jaccard: 0.5897 - val_loss: 0.2310 - val_jaccard: 0.4664\n",
      "Epoch 327/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1260 - jaccard: 0.5850 - val_loss: 0.2253 - val_jaccard: 0.4650\n",
      "Epoch 328/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1217 - jaccard: 0.5967 - val_loss: 0.2136 - val_jaccard: 0.4787\n",
      "Epoch 329/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1229 - jaccard: 0.5917 - val_loss: 0.2255 - val_jaccard: 0.4700\n",
      "Epoch 330/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1219 - jaccard: 0.5987 - val_loss: 0.2271 - val_jaccard: 0.4746\n",
      "Epoch 331/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1227 - jaccard: 0.5931 - val_loss: 0.2187 - val_jaccard: 0.4741\n",
      "Epoch 332/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1228 - jaccard: 0.5976 - val_loss: 0.2332 - val_jaccard: 0.4596\n",
      "Epoch 333/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1218 - jaccard: 0.5957 - val_loss: 0.2253 - val_jaccard: 0.4625\n",
      "Epoch 334/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1225 - jaccard: 0.5965 - val_loss: 0.2280 - val_jaccard: 0.4715\n",
      "Epoch 335/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1201 - jaccard: 0.6046 - val_loss: 0.2361 - val_jaccard: 0.4706\n",
      "Epoch 336/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1210 - jaccard: 0.5967 - val_loss: 0.2253 - val_jaccard: 0.4758\n",
      "Epoch 337/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1189 - jaccard: 0.6071 - val_loss: 0.2226 - val_jaccard: 0.4732\n",
      "Epoch 338/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1207 - jaccard: 0.5993 - val_loss: 0.2242 - val_jaccard: 0.4754\n",
      "Epoch 339/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1208 - jaccard: 0.5971 - val_loss: 0.2291 - val_jaccard: 0.4712\n",
      "Epoch 340/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1189 - jaccard: 0.6079 - val_loss: 0.2247 - val_jaccard: 0.4700\n",
      "Epoch 341/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1193 - jaccard: 0.6047 - val_loss: 0.2337 - val_jaccard: 0.4672\n",
      "Epoch 342/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1227 - jaccard: 0.5967 - val_loss: 0.2549 - val_jaccard: 0.4616\n",
      "Epoch 343/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1312 - jaccard: 0.5841 - val_loss: 0.2099 - val_jaccard: 0.4733\n",
      "Epoch 344/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1291 - jaccard: 0.5820 - val_loss: 0.2167 - val_jaccard: 0.4735\n",
      "Epoch 345/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1206 - jaccard: 0.6002 - val_loss: 0.2207 - val_jaccard: 0.4748\n",
      "Epoch 346/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1203 - jaccard: 0.6054 - val_loss: 0.2278 - val_jaccard: 0.4704\n",
      "Epoch 347/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1190 - jaccard: 0.6024 - val_loss: 0.2242 - val_jaccard: 0.4738\n",
      "Epoch 348/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1173 - jaccard: 0.6116 - val_loss: 0.2312 - val_jaccard: 0.4753\n",
      "Epoch 349/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1203 - jaccard: 0.6044 - val_loss: 0.2316 - val_jaccard: 0.4697\n",
      "Epoch 350/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1180 - jaccard: 0.6064 - val_loss: 0.2262 - val_jaccard: 0.4717\n",
      "Epoch 351/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1187 - jaccard: 0.6052 - val_loss: 0.2212 - val_jaccard: 0.4745\n",
      "Epoch 352/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1175 - jaccard: 0.6098 - val_loss: 0.2221 - val_jaccard: 0.4708\n",
      "Epoch 353/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1201 - jaccard: 0.6024 - val_loss: 0.2181 - val_jaccard: 0.4795\n",
      "Epoch 354/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1182 - jaccard: 0.6071 - val_loss: 0.2275 - val_jaccard: 0.4700\n",
      "Epoch 355/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1165 - jaccard: 0.6130 - val_loss: 0.2250 - val_jaccard: 0.4781\n",
      "Epoch 356/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1191 - jaccard: 0.6092 - val_loss: 0.2252 - val_jaccard: 0.4605\n",
      "Epoch 357/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1175 - jaccard: 0.6100 - val_loss: 0.2326 - val_jaccard: 0.4752\n",
      "Epoch 358/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1183 - jaccard: 0.6077 - val_loss: 0.2184 - val_jaccard: 0.4775\n",
      "Epoch 359/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1166 - jaccard: 0.6114 - val_loss: 0.2228 - val_jaccard: 0.4777\n",
      "Epoch 360/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1170 - jaccard: 0.6094 - val_loss: 0.2261 - val_jaccard: 0.4773\n",
      "Epoch 361/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1162 - jaccard: 0.6138 - val_loss: 0.2337 - val_jaccard: 0.4779\n",
      "Epoch 362/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1174 - jaccard: 0.6111 - val_loss: 0.2188 - val_jaccard: 0.4786\n",
      "Epoch 363/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1165 - jaccard: 0.6136 - val_loss: 0.2214 - val_jaccard: 0.4740\n",
      "Epoch 364/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1142 - jaccard: 0.6197 - val_loss: 0.2255 - val_jaccard: 0.4767\n",
      "Epoch 365/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1168 - jaccard: 0.6141 - val_loss: 0.2256 - val_jaccard: 0.4815\n",
      "Epoch 366/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1279 - jaccard: 0.5968 - val_loss: 0.2165 - val_jaccard: 0.4605\n",
      "Epoch 367/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1266 - jaccard: 0.5898 - val_loss: 0.2423 - val_jaccard: 0.4649\n",
      "Epoch 368/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1222 - jaccard: 0.6012 - val_loss: 0.2525 - val_jaccard: 0.4593\n",
      "Epoch 369/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1178 - jaccard: 0.6115 - val_loss: 0.2316 - val_jaccard: 0.4695\n",
      "Epoch 370/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1170 - jaccard: 0.6115 - val_loss: 0.2357 - val_jaccard: 0.4683\n",
      "Epoch 371/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1190 - jaccard: 0.6063 - val_loss: 0.2299 - val_jaccard: 0.4707\n",
      "Epoch 372/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1158 - jaccard: 0.6129 - val_loss: 0.2312 - val_jaccard: 0.4755\n",
      "Epoch 373/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1150 - jaccard: 0.6177 - val_loss: 0.2266 - val_jaccard: 0.4738\n",
      "Epoch 374/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1163 - jaccard: 0.6097 - val_loss: 0.2233 - val_jaccard: 0.4767\n",
      "Epoch 375/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1141 - jaccard: 0.6197 - val_loss: 0.2364 - val_jaccard: 0.4704\n",
      "Epoch 376/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1148 - jaccard: 0.6183 - val_loss: 0.2303 - val_jaccard: 0.4745\n",
      "Epoch 377/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1154 - jaccard: 0.6187 - val_loss: 0.2270 - val_jaccard: 0.4747\n",
      "Epoch 378/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1155 - jaccard: 0.6139 - val_loss: 0.2291 - val_jaccard: 0.4764\n",
      "Epoch 379/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1137 - jaccard: 0.6225 - val_loss: 0.2286 - val_jaccard: 0.4751\n",
      "Epoch 380/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1146 - jaccard: 0.6197 - val_loss: 0.2273 - val_jaccard: 0.4775\n",
      "Epoch 381/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1147 - jaccard: 0.6165 - val_loss: 0.2357 - val_jaccard: 0.4768\n",
      "Epoch 382/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1125 - jaccard: 0.6233 - val_loss: 0.2281 - val_jaccard: 0.4815\n",
      "Epoch 383/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1142 - jaccard: 0.6184 - val_loss: 0.2355 - val_jaccard: 0.4759\n",
      "Epoch 384/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1132 - jaccard: 0.6207 - val_loss: 0.2344 - val_jaccard: 0.4801\n",
      "Epoch 385/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1138 - jaccard: 0.6203 - val_loss: 0.2303 - val_jaccard: 0.4772\n",
      "Epoch 386/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1155 - jaccard: 0.6153 - val_loss: 0.2275 - val_jaccard: 0.4806\n",
      "Epoch 387/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1139 - jaccard: 0.6158 - val_loss: 0.2272 - val_jaccard: 0.4772\n",
      "Epoch 388/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1127 - jaccard: 0.6213 - val_loss: 0.2298 - val_jaccard: 0.4850\n",
      "Epoch 389/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1129 - jaccard: 0.6224 - val_loss: 0.2350 - val_jaccard: 0.4780\n",
      "Epoch 390/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1153 - jaccard: 0.6212 - val_loss: 0.2333 - val_jaccard: 0.4661\n",
      "Epoch 391/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1138 - jaccard: 0.6182 - val_loss: 0.2299 - val_jaccard: 0.4778\n",
      "Epoch 392/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1141 - jaccard: 0.6182 - val_loss: 0.2314 - val_jaccard: 0.4816\n",
      "Epoch 393/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1113 - jaccard: 0.6274 - val_loss: 0.2229 - val_jaccard: 0.4832\n",
      "Epoch 394/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1117 - jaccard: 0.6252 - val_loss: 0.2256 - val_jaccard: 0.4772\n",
      "Epoch 395/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1116 - jaccard: 0.6280 - val_loss: 0.2348 - val_jaccard: 0.4679\n",
      "Epoch 396/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1119 - jaccard: 0.6296 - val_loss: 0.2285 - val_jaccard: 0.4820\n",
      "Epoch 397/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1118 - jaccard: 0.6262 - val_loss: 0.2310 - val_jaccard: 0.4791\n",
      "Epoch 398/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1125 - jaccard: 0.6209 - val_loss: 0.2281 - val_jaccard: 0.4806\n",
      "Epoch 399/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1104 - jaccard: 0.6277 - val_loss: 0.2320 - val_jaccard: 0.4772\n",
      "Epoch 400/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1103 - jaccard: 0.6290 - val_loss: 0.2280 - val_jaccard: 0.4766\n",
      "Epoch 401/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1104 - jaccard: 0.6274 - val_loss: 0.2291 - val_jaccard: 0.4821\n",
      "Epoch 402/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1105 - jaccard: 0.6300 - val_loss: 0.2288 - val_jaccard: 0.4838\n",
      "Epoch 403/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1096 - jaccard: 0.6320 - val_loss: 0.2310 - val_jaccard: 0.4823\n",
      "Epoch 404/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1094 - jaccard: 0.6344 - val_loss: 0.2318 - val_jaccard: 0.4800\n",
      "Epoch 405/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1120 - jaccard: 0.6280 - val_loss: 0.2375 - val_jaccard: 0.4791\n",
      "Epoch 406/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1101 - jaccard: 0.6321 - val_loss: 0.2382 - val_jaccard: 0.4825\n",
      "Epoch 407/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1115 - jaccard: 0.6270 - val_loss: 0.2323 - val_jaccard: 0.4756\n",
      "Epoch 408/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1104 - jaccard: 0.6300 - val_loss: 0.2373 - val_jaccard: 0.4789\n",
      "Epoch 409/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1094 - jaccard: 0.6344 - val_loss: 0.2417 - val_jaccard: 0.4781\n",
      "Epoch 410/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1136 - jaccard: 0.6245 - val_loss: 0.2385 - val_jaccard: 0.4678\n",
      "Epoch 411/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1103 - jaccard: 0.6310 - val_loss: 0.2337 - val_jaccard: 0.4772\n",
      "Epoch 412/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1089 - jaccard: 0.6349 - val_loss: 0.2299 - val_jaccard: 0.4800\n",
      "Epoch 413/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1097 - jaccard: 0.6294 - val_loss: 0.2348 - val_jaccard: 0.4771\n",
      "Epoch 414/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1084 - jaccard: 0.6343 - val_loss: 0.2514 - val_jaccard: 0.4738\n",
      "Epoch 415/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1095 - jaccard: 0.6364 - val_loss: 0.2288 - val_jaccard: 0.4787\n",
      "Epoch 416/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1094 - jaccard: 0.6339 - val_loss: 0.2342 - val_jaccard: 0.4841\n",
      "Epoch 417/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1095 - jaccard: 0.6329 - val_loss: 0.2386 - val_jaccard: 0.4798\n",
      "Epoch 418/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1084 - jaccard: 0.6360 - val_loss: 0.2367 - val_jaccard: 0.4810\n",
      "Epoch 419/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1115 - jaccard: 0.6289 - val_loss: 0.2278 - val_jaccard: 0.4800\n",
      "Epoch 420/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1131 - jaccard: 0.6292 - val_loss: 0.2300 - val_jaccard: 0.4700\n",
      "Epoch 421/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1099 - jaccard: 0.6292 - val_loss: 0.2295 - val_jaccard: 0.4819\n",
      "Epoch 422/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1079 - jaccard: 0.6351 - val_loss: 0.2405 - val_jaccard: 0.4774\n",
      "Epoch 423/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1074 - jaccard: 0.6358 - val_loss: 0.2317 - val_jaccard: 0.4850\n",
      "Epoch 424/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1088 - jaccard: 0.6336 - val_loss: 0.2354 - val_jaccard: 0.4870\n",
      "Epoch 425/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1087 - jaccard: 0.6330 - val_loss: 0.2380 - val_jaccard: 0.4825\n",
      "Epoch 426/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1081 - jaccard: 0.6359 - val_loss: 0.2362 - val_jaccard: 0.4777\n",
      "Epoch 427/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1082 - jaccard: 0.6359 - val_loss: 0.2496 - val_jaccard: 0.4770\n",
      "Epoch 428/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1073 - jaccard: 0.6401 - val_loss: 0.2396 - val_jaccard: 0.4844\n",
      "Epoch 429/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1081 - jaccard: 0.6377 - val_loss: 0.2332 - val_jaccard: 0.4809\n",
      "Epoch 430/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1079 - jaccard: 0.6362 - val_loss: 0.2269 - val_jaccard: 0.4829\n",
      "Epoch 431/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1063 - jaccard: 0.6396 - val_loss: 0.2298 - val_jaccard: 0.4865\n",
      "Epoch 432/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1081 - jaccard: 0.6347 - val_loss: 0.2308 - val_jaccard: 0.4823\n",
      "Epoch 433/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1078 - jaccard: 0.6373 - val_loss: 0.2443 - val_jaccard: 0.4793\n",
      "Epoch 434/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1101 - jaccard: 0.6312 - val_loss: 0.2322 - val_jaccard: 0.4860\n",
      "Epoch 435/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1080 - jaccard: 0.6364 - val_loss: 0.2309 - val_jaccard: 0.4791\n",
      "Epoch 436/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1074 - jaccard: 0.6372 - val_loss: 0.2377 - val_jaccard: 0.4849\n",
      "Epoch 437/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1058 - jaccard: 0.6416 - val_loss: 0.2388 - val_jaccard: 0.4829\n",
      "Epoch 438/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1062 - jaccard: 0.6430 - val_loss: 0.2339 - val_jaccard: 0.4846\n",
      "Epoch 439/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1062 - jaccard: 0.6442 - val_loss: 0.2329 - val_jaccard: 0.4856\n",
      "Epoch 440/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1084 - jaccard: 0.6358 - val_loss: 0.2450 - val_jaccard: 0.4783\n",
      "Epoch 441/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1064 - jaccard: 0.6402 - val_loss: 0.2424 - val_jaccard: 0.4781\n",
      "Epoch 442/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1061 - jaccard: 0.6405 - val_loss: 0.2694 - val_jaccard: 0.4666\n",
      "Epoch 443/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1059 - jaccard: 0.6431 - val_loss: 0.2426 - val_jaccard: 0.4808\n",
      "Epoch 444/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1077 - jaccard: 0.6376 - val_loss: 0.2402 - val_jaccard: 0.4787\n",
      "Epoch 445/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1053 - jaccard: 0.6408 - val_loss: 0.2376 - val_jaccard: 0.4826\n",
      "Epoch 446/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1061 - jaccard: 0.6375 - val_loss: 0.2397 - val_jaccard: 0.4758\n",
      "Epoch 447/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1049 - jaccard: 0.6453 - val_loss: 0.2428 - val_jaccard: 0.4810\n",
      "Epoch 448/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1074 - jaccard: 0.6404 - val_loss: 0.2365 - val_jaccard: 0.4774\n",
      "Epoch 449/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1055 - jaccard: 0.6400 - val_loss: 0.2408 - val_jaccard: 0.4812\n",
      "Epoch 450/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1043 - jaccard: 0.6464 - val_loss: 0.2440 - val_jaccard: 0.4800\n",
      "Epoch 451/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1046 - jaccard: 0.6452 - val_loss: 0.2391 - val_jaccard: 0.4805\n",
      "Epoch 452/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1045 - jaccard: 0.6470 - val_loss: 0.2502 - val_jaccard: 0.4819\n",
      "Epoch 453/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1080 - jaccard: 0.6383 - val_loss: 0.2392 - val_jaccard: 0.4851\n",
      "Epoch 454/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1057 - jaccard: 0.6399 - val_loss: 0.2390 - val_jaccard: 0.4653\n",
      "Epoch 455/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1050 - jaccard: 0.6412 - val_loss: 0.2373 - val_jaccard: 0.4836\n",
      "Epoch 456/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1043 - jaccard: 0.6448 - val_loss: 0.2282 - val_jaccard: 0.4835\n",
      "Epoch 457/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1034 - jaccard: 0.6467 - val_loss: 0.2349 - val_jaccard: 0.4843\n",
      "Epoch 458/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1031 - jaccard: 0.6505 - val_loss: 0.2301 - val_jaccard: 0.4841\n",
      "Epoch 459/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1055 - jaccard: 0.6408 - val_loss: 0.2332 - val_jaccard: 0.4855\n",
      "Epoch 460/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1038 - jaccard: 0.6490 - val_loss: 0.2330 - val_jaccard: 0.4807\n",
      "Epoch 461/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1038 - jaccard: 0.6477 - val_loss: 0.2376 - val_jaccard: 0.4824\n",
      "Epoch 462/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1044 - jaccard: 0.6455 - val_loss: 0.2321 - val_jaccard: 0.4874\n",
      "Epoch 463/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1064 - jaccard: 0.6373 - val_loss: 0.2390 - val_jaccard: 0.4815\n",
      "Epoch 464/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1045 - jaccard: 0.6423 - val_loss: 0.2427 - val_jaccard: 0.4770\n",
      "Epoch 465/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1054 - jaccard: 0.6403 - val_loss: 0.2298 - val_jaccard: 0.4860\n",
      "Epoch 466/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1066 - jaccard: 0.6384 - val_loss: 0.2355 - val_jaccard: 0.4783\n",
      "Epoch 467/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1047 - jaccard: 0.6457 - val_loss: 0.2456 - val_jaccard: 0.4854\n",
      "Epoch 468/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1031 - jaccard: 0.6489 - val_loss: 0.2391 - val_jaccard: 0.4882\n",
      "Epoch 469/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1035 - jaccard: 0.6457 - val_loss: 0.2309 - val_jaccard: 0.4859\n",
      "Epoch 470/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1024 - jaccard: 0.6521 - val_loss: 0.2417 - val_jaccard: 0.4755\n",
      "Epoch 471/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1027 - jaccard: 0.6500 - val_loss: 0.2340 - val_jaccard: 0.4871\n",
      "Epoch 472/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1032 - jaccard: 0.6501 - val_loss: 0.2461 - val_jaccard: 0.4818\n",
      "Epoch 473/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1031 - jaccard: 0.6485 - val_loss: 0.2399 - val_jaccard: 0.4821\n",
      "Epoch 474/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1043 - jaccard: 0.6490 - val_loss: 0.2370 - val_jaccard: 0.4768\n",
      "Epoch 475/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1040 - jaccard: 0.6439 - val_loss: 0.2579 - val_jaccard: 0.4791\n",
      "Epoch 476/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1042 - jaccard: 0.6480 - val_loss: 0.2384 - val_jaccard: 0.4787\n",
      "Epoch 477/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1017 - jaccard: 0.6528 - val_loss: 0.2441 - val_jaccard: 0.4814\n",
      "Epoch 478/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1025 - jaccard: 0.6507 - val_loss: 0.2400 - val_jaccard: 0.4854\n",
      "Epoch 479/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1041 - jaccard: 0.6466 - val_loss: 0.2471 - val_jaccard: 0.4785\n",
      "Epoch 480/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1019 - jaccard: 0.6516 - val_loss: 0.2361 - val_jaccard: 0.4844\n",
      "Epoch 481/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0998 - jaccard: 0.6591 - val_loss: 0.2421 - val_jaccard: 0.4806\n",
      "Epoch 482/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1017 - jaccard: 0.6553 - val_loss: 0.2382 - val_jaccard: 0.4779\n",
      "Epoch 483/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1010 - jaccard: 0.6574 - val_loss: 0.2510 - val_jaccard: 0.4835\n",
      "Epoch 484/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1011 - jaccard: 0.6549 - val_loss: 0.2476 - val_jaccard: 0.4853\n",
      "Epoch 485/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1013 - jaccard: 0.6551 - val_loss: 0.2408 - val_jaccard: 0.4880\n",
      "Epoch 486/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1009 - jaccard: 0.6556 - val_loss: 0.2419 - val_jaccard: 0.4878\n",
      "Epoch 487/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1008 - jaccard: 0.6548 - val_loss: 0.2379 - val_jaccard: 0.4881\n",
      "Epoch 488/1000\n",
      "260/260 [==============================] - 22s - loss: 0.1000 - jaccard: 0.6574 - val_loss: 0.2462 - val_jaccard: 0.4878\n",
      "Epoch 489/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1004 - jaccard: 0.6557 - val_loss: 0.2392 - val_jaccard: 0.4842\n",
      "Epoch 490/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1023 - jaccard: 0.6529 - val_loss: 0.2410 - val_jaccard: 0.4814\n",
      "Epoch 491/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1019 - jaccard: 0.6530 - val_loss: 0.2379 - val_jaccard: 0.4811\n",
      "Epoch 492/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1006 - jaccard: 0.6565 - val_loss: 0.2425 - val_jaccard: 0.4849\n",
      "Epoch 493/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1008 - jaccard: 0.6544 - val_loss: 0.2483 - val_jaccard: 0.4804\n",
      "Epoch 494/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1004 - jaccard: 0.6566 - val_loss: 0.2509 - val_jaccard: 0.4834\n",
      "Epoch 495/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1006 - jaccard: 0.6575 - val_loss: 0.2394 - val_jaccard: 0.4841\n",
      "Epoch 496/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1007 - jaccard: 0.6595 - val_loss: 0.2591 - val_jaccard: 0.4764\n",
      "Epoch 497/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0992 - jaccard: 0.6587 - val_loss: 0.2427 - val_jaccard: 0.4841\n",
      "Epoch 498/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1015 - jaccard: 0.6548 - val_loss: 0.2389 - val_jaccard: 0.4847\n",
      "Epoch 499/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1008 - jaccard: 0.6571 - val_loss: 0.2361 - val_jaccard: 0.4891\n",
      "Epoch 500/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0992 - jaccard: 0.6574 - val_loss: 0.2446 - val_jaccard: 0.4834\n",
      "Epoch 501/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0989 - jaccard: 0.6594 - val_loss: 0.2481 - val_jaccard: 0.4862\n",
      "Epoch 502/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0979 - jaccard: 0.6660 - val_loss: 0.2437 - val_jaccard: 0.4849\n",
      "Epoch 503/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1016 - jaccard: 0.6547 - val_loss: 0.2375 - val_jaccard: 0.4901\n",
      "Epoch 504/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1000 - jaccard: 0.6588 - val_loss: 0.2382 - val_jaccard: 0.4802\n",
      "Epoch 505/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0990 - jaccard: 0.6600 - val_loss: 0.2704 - val_jaccard: 0.4760\n",
      "Epoch 506/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1013 - jaccard: 0.6557 - val_loss: 0.2434 - val_jaccard: 0.4873\n",
      "Epoch 507/1000\n",
      "260/260 [==============================] - 21s - loss: 0.1002 - jaccard: 0.6555 - val_loss: 0.2496 - val_jaccard: 0.4799\n",
      "Epoch 508/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0992 - jaccard: 0.6630 - val_loss: 0.2428 - val_jaccard: 0.4915\n",
      "Epoch 509/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0986 - jaccard: 0.6633 - val_loss: 0.2412 - val_jaccard: 0.4900\n",
      "Epoch 510/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0997 - jaccard: 0.6570 - val_loss: 0.2440 - val_jaccard: 0.4807\n",
      "Epoch 511/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0991 - jaccard: 0.6617 - val_loss: 0.2516 - val_jaccard: 0.4867\n",
      "Epoch 512/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0984 - jaccard: 0.6623 - val_loss: 0.2444 - val_jaccard: 0.4884\n",
      "Epoch 513/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0999 - jaccard: 0.6567 - val_loss: 0.2380 - val_jaccard: 0.4869\n",
      "Epoch 514/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0986 - jaccard: 0.6631 - val_loss: 0.2534 - val_jaccard: 0.4832\n",
      "Epoch 515/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0979 - jaccard: 0.6640 - val_loss: 0.2355 - val_jaccard: 0.4915\n",
      "Epoch 516/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0972 - jaccard: 0.6648 - val_loss: 0.2424 - val_jaccard: 0.4916\n",
      "Epoch 517/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0985 - jaccard: 0.6639 - val_loss: 0.2432 - val_jaccard: 0.4894\n",
      "Epoch 518/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0978 - jaccard: 0.6612 - val_loss: 0.2497 - val_jaccard: 0.4898\n",
      "Epoch 519/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0999 - jaccard: 0.6624 - val_loss: 0.2511 - val_jaccard: 0.4854\n",
      "Epoch 520/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0983 - jaccard: 0.6626 - val_loss: 0.2476 - val_jaccard: 0.4885\n",
      "Epoch 521/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0982 - jaccard: 0.6631 - val_loss: 0.2477 - val_jaccard: 0.4893\n",
      "Epoch 522/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0997 - jaccard: 0.6579 - val_loss: 0.2500 - val_jaccard: 0.4881\n",
      "Epoch 523/1000\n",
      "255/260 [============================>.] - ETA: 0s - loss: 0.0978 - jaccard: 0.6619\n",
      "Epoch 00522: reducing learning rate to 0.0001250000059371814.\n",
      "260/260 [==============================] - 21s - loss: 0.0986 - jaccard: 0.6620 - val_loss: 0.2428 - val_jaccard: 0.4884\n",
      "Epoch 524/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0968 - jaccard: 0.6636 - val_loss: 0.2485 - val_jaccard: 0.4872\n",
      "Epoch 525/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0968 - jaccard: 0.6663 - val_loss: 0.2505 - val_jaccard: 0.4864\n",
      "Epoch 526/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0953 - jaccard: 0.6700 - val_loss: 0.2458 - val_jaccard: 0.4873\n",
      "Epoch 527/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0966 - jaccard: 0.6683 - val_loss: 0.2426 - val_jaccard: 0.4894\n",
      "Epoch 528/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0961 - jaccard: 0.6685 - val_loss: 0.2488 - val_jaccard: 0.4853\n",
      "Epoch 529/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0949 - jaccard: 0.6705 - val_loss: 0.2405 - val_jaccard: 0.4923\n",
      "Epoch 530/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0950 - jaccard: 0.6724 - val_loss: 0.2440 - val_jaccard: 0.4857\n",
      "Epoch 531/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0944 - jaccard: 0.6717 - val_loss: 0.2489 - val_jaccard: 0.4883\n",
      "Epoch 532/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0940 - jaccard: 0.6755 - val_loss: 0.2469 - val_jaccard: 0.4902\n",
      "Epoch 533/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0953 - jaccard: 0.6674 - val_loss: 0.2415 - val_jaccard: 0.4929\n",
      "Epoch 534/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0944 - jaccard: 0.6754 - val_loss: 0.2453 - val_jaccard: 0.4879\n",
      "Epoch 535/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0941 - jaccard: 0.6756 - val_loss: 0.2474 - val_jaccard: 0.4897\n",
      "Epoch 536/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0946 - jaccard: 0.6744 - val_loss: 0.2430 - val_jaccard: 0.4901\n",
      "Epoch 537/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0938 - jaccard: 0.6741 - val_loss: 0.2436 - val_jaccard: 0.4857\n",
      "Epoch 538/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0955 - jaccard: 0.6681 - val_loss: 0.2473 - val_jaccard: 0.4897\n",
      "Epoch 539/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0946 - jaccard: 0.6715 - val_loss: 0.2417 - val_jaccard: 0.4921\n",
      "Epoch 540/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0940 - jaccard: 0.6734 - val_loss: 0.2407 - val_jaccard: 0.4937\n",
      "Epoch 541/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0942 - jaccard: 0.6748 - val_loss: 0.2435 - val_jaccard: 0.4927\n",
      "Epoch 542/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0933 - jaccard: 0.6779 - val_loss: 0.2415 - val_jaccard: 0.4923\n",
      "Epoch 543/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0937 - jaccard: 0.6773 - val_loss: 0.2485 - val_jaccard: 0.4877\n",
      "Epoch 544/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0940 - jaccard: 0.6749 - val_loss: 0.2479 - val_jaccard: 0.4886\n",
      "Epoch 545/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0934 - jaccard: 0.6738 - val_loss: 0.2439 - val_jaccard: 0.4886\n",
      "Epoch 546/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0943 - jaccard: 0.6693 - val_loss: 0.2426 - val_jaccard: 0.4923\n",
      "Epoch 547/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0947 - jaccard: 0.6747 - val_loss: 0.2432 - val_jaccard: 0.4924\n",
      "Epoch 548/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0936 - jaccard: 0.6732 - val_loss: 0.2467 - val_jaccard: 0.4903\n",
      "Epoch 549/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0940 - jaccard: 0.6759 - val_loss: 0.2392 - val_jaccard: 0.4920\n",
      "Epoch 550/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0949 - jaccard: 0.6723 - val_loss: 0.2361 - val_jaccard: 0.4885\n",
      "Epoch 551/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0939 - jaccard: 0.6754 - val_loss: 0.2449 - val_jaccard: 0.4907\n",
      "Epoch 552/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0958 - jaccard: 0.6686 - val_loss: 0.2480 - val_jaccard: 0.4872\n",
      "Epoch 553/1000\n",
      "255/260 [============================>.] - ETA: 0s - loss: 0.0922 - jaccard: 0.6752\n",
      "Epoch 00552: reducing learning rate to 6.25000029685907e-05.\n",
      "260/260 [==============================] - 21s - loss: 0.0937 - jaccard: 0.6750 - val_loss: 0.2400 - val_jaccard: 0.4942\n",
      "Epoch 554/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0947 - jaccard: 0.6712 - val_loss: 0.2459 - val_jaccard: 0.4915\n",
      "Epoch 555/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0943 - jaccard: 0.6752 - val_loss: 0.2434 - val_jaccard: 0.4927\n",
      "Epoch 556/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0933 - jaccard: 0.6743 - val_loss: 0.2448 - val_jaccard: 0.4919\n",
      "Epoch 557/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0943 - jaccard: 0.6756 - val_loss: 0.2432 - val_jaccard: 0.4914\n",
      "Epoch 558/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0921 - jaccard: 0.6802 - val_loss: 0.2451 - val_jaccard: 0.4918\n",
      "Epoch 559/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0923 - jaccard: 0.6795 - val_loss: 0.2496 - val_jaccard: 0.4912\n",
      "Epoch 560/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0914 - jaccard: 0.6814 - val_loss: 0.2448 - val_jaccard: 0.4924\n",
      "Epoch 561/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0930 - jaccard: 0.6761 - val_loss: 0.2468 - val_jaccard: 0.4910\n",
      "Epoch 562/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0947 - jaccard: 0.6747 - val_loss: 0.2472 - val_jaccard: 0.4912\n",
      "Epoch 563/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0920 - jaccard: 0.6794 - val_loss: 0.2469 - val_jaccard: 0.4906\n",
      "Epoch 564/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0933 - jaccard: 0.6789 - val_loss: 0.2458 - val_jaccard: 0.4917\n",
      "Epoch 565/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0939 - jaccard: 0.6747 - val_loss: 0.2435 - val_jaccard: 0.4914\n",
      "Epoch 566/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0916 - jaccard: 0.6810 - val_loss: 0.2476 - val_jaccard: 0.4907\n",
      "Epoch 567/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0916 - jaccard: 0.6791 - val_loss: 0.2491 - val_jaccard: 0.4918\n",
      "Epoch 568/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0927 - jaccard: 0.6761 - val_loss: 0.2509 - val_jaccard: 0.4913\n",
      "Epoch 569/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0918 - jaccard: 0.6801 - val_loss: 0.2491 - val_jaccard: 0.4911\n",
      "Epoch 570/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0923 - jaccard: 0.6760 - val_loss: 0.2513 - val_jaccard: 0.4908\n",
      "Epoch 571/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0928 - jaccard: 0.6774 - val_loss: 0.2503 - val_jaccard: 0.4894\n",
      "Epoch 572/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0927 - jaccard: 0.6752 - val_loss: 0.2456 - val_jaccard: 0.4920\n",
      "Epoch 573/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0916 - jaccard: 0.6811 - val_loss: 0.2436 - val_jaccard: 0.4934\n",
      "Epoch 574/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0938 - jaccard: 0.6766 - val_loss: 0.2434 - val_jaccard: 0.4922\n",
      "Epoch 575/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0913 - jaccard: 0.6816 - val_loss: 0.2472 - val_jaccard: 0.4925\n",
      "Epoch 576/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0958 - jaccard: 0.6798 - val_loss: 0.2529 - val_jaccard: 0.4926\n",
      "Epoch 577/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0930 - jaccard: 0.6765 - val_loss: 0.2455 - val_jaccard: 0.4928\n",
      "Epoch 578/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0922 - jaccard: 0.6749 - val_loss: 0.2474 - val_jaccard: 0.4894\n",
      "Epoch 579/1000\n",
      "255/260 [============================>.] - ETA: 0s - loss: 0.0915 - jaccard: 0.6795\n",
      "Epoch 00578: reducing learning rate to 3.125000148429535e-05.\n",
      "260/260 [==============================] - 21s - loss: 0.0916 - jaccard: 0.6795 - val_loss: 0.2493 - val_jaccard: 0.4916\n",
      "Epoch 580/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0926 - jaccard: 0.6794 - val_loss: 0.2440 - val_jaccard: 0.4928\n",
      "Epoch 581/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0907 - jaccard: 0.6850 - val_loss: 0.2490 - val_jaccard: 0.4897\n",
      "Epoch 582/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0925 - jaccard: 0.6752 - val_loss: 0.2547 - val_jaccard: 0.4900\n",
      "Epoch 583/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0914 - jaccard: 0.6793 - val_loss: 0.2504 - val_jaccard: 0.4915\n",
      "Epoch 584/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0906 - jaccard: 0.6837 - val_loss: 0.2489 - val_jaccard: 0.4909\n",
      "Epoch 585/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0913 - jaccard: 0.6819 - val_loss: 0.2518 - val_jaccard: 0.4898\n",
      "Epoch 586/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0912 - jaccard: 0.6798 - val_loss: 0.2492 - val_jaccard: 0.4915\n",
      "Epoch 587/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0915 - jaccard: 0.6820 - val_loss: 0.2491 - val_jaccard: 0.4917\n",
      "Epoch 588/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0913 - jaccard: 0.6789 - val_loss: 0.2489 - val_jaccard: 0.4912\n",
      "Epoch 589/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0917 - jaccard: 0.6833 - val_loss: 0.2478 - val_jaccard: 0.4918\n",
      "Epoch 590/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0908 - jaccard: 0.6843 - val_loss: 0.2474 - val_jaccard: 0.4906\n",
      "Epoch 591/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0912 - jaccard: 0.6820 - val_loss: 0.2499 - val_jaccard: 0.4905\n",
      "Epoch 592/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0909 - jaccard: 0.6776 - val_loss: 0.2508 - val_jaccard: 0.4905\n",
      "Epoch 593/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0916 - jaccard: 0.6773 - val_loss: 0.2491 - val_jaccard: 0.4920\n",
      "Epoch 594/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0923 - jaccard: 0.6792 - val_loss: 0.2529 - val_jaccard: 0.4889\n",
      "Epoch 595/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0925 - jaccard: 0.6773 - val_loss: 0.2512 - val_jaccard: 0.4911\n",
      "Epoch 596/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0910 - jaccard: 0.6813 - val_loss: 0.2500 - val_jaccard: 0.4917\n",
      "Epoch 597/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0908 - jaccard: 0.6809 - val_loss: 0.2504 - val_jaccard: 0.4933\n",
      "Epoch 598/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0917 - jaccard: 0.6793 - val_loss: 0.2577 - val_jaccard: 0.4892\n",
      "Epoch 599/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0914 - jaccard: 0.6822 - val_loss: 0.2542 - val_jaccard: 0.4906\n",
      "Epoch 600/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0909 - jaccard: 0.6828 - val_loss: 0.2497 - val_jaccard: 0.4918\n",
      "Epoch 601/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0901 - jaccard: 0.6860 - val_loss: 0.2501 - val_jaccard: 0.4918\n",
      "Epoch 602/1000\n",
      "255/260 [============================>.] - ETA: 0s - loss: 0.0908 - jaccard: 0.6843\n",
      "Epoch 00601: reducing learning rate to 1.5625000742147677e-05.\n",
      "260/260 [==============================] - 21s - loss: 0.0907 - jaccard: 0.6838 - val_loss: 0.2501 - val_jaccard: 0.4895\n",
      "Epoch 603/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0908 - jaccard: 0.6815 - val_loss: 0.2501 - val_jaccard: 0.4908\n",
      "Epoch 604/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0906 - jaccard: 0.6842 - val_loss: 0.2515 - val_jaccard: 0.4913\n",
      "Epoch 605/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0905 - jaccard: 0.6844 - val_loss: 0.2515 - val_jaccard: 0.4908\n",
      "Epoch 606/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0914 - jaccard: 0.6820 - val_loss: 0.2538 - val_jaccard: 0.4908\n",
      "Epoch 607/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0904 - jaccard: 0.6868 - val_loss: 0.2524 - val_jaccard: 0.4907\n",
      "Epoch 608/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0898 - jaccard: 0.6870 - val_loss: 0.2501 - val_jaccard: 0.4919\n",
      "Epoch 609/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0900 - jaccard: 0.6841 - val_loss: 0.2504 - val_jaccard: 0.4904\n",
      "Epoch 610/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0904 - jaccard: 0.6845 - val_loss: 0.2515 - val_jaccard: 0.4902\n",
      "Epoch 611/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0912 - jaccard: 0.6815 - val_loss: 0.2512 - val_jaccard: 0.4910\n",
      "Epoch 612/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0913 - jaccard: 0.6783 - val_loss: 0.2496 - val_jaccard: 0.4936\n",
      "Epoch 613/1000\n",
      "260/260 [==============================] - 22s - loss: 0.0916 - jaccard: 0.6798 - val_loss: 0.2498 - val_jaccard: 0.4927\n",
      "Epoch 614/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0901 - jaccard: 0.6861 - val_loss: 0.2490 - val_jaccard: 0.4926\n",
      "Epoch 615/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0903 - jaccard: 0.6887 - val_loss: 0.2487 - val_jaccard: 0.4930\n",
      "Epoch 616/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0904 - jaccard: 0.6805 - val_loss: 0.2514 - val_jaccard: 0.4918\n",
      "Epoch 617/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0903 - jaccard: 0.6828 - val_loss: 0.2503 - val_jaccard: 0.4924\n",
      "Epoch 618/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0919 - jaccard: 0.6810 - val_loss: 0.2499 - val_jaccard: 0.4935\n",
      "Epoch 619/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0905 - jaccard: 0.6830 - val_loss: 0.2498 - val_jaccard: 0.4923\n",
      "Epoch 620/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0907 - jaccard: 0.6815 - val_loss: 0.2485 - val_jaccard: 0.4912\n",
      "Epoch 621/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0918 - jaccard: 0.6823 - val_loss: 0.2499 - val_jaccard: 0.4929\n",
      "Epoch 622/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0901 - jaccard: 0.6851 - val_loss: 0.2516 - val_jaccard: 0.4908\n",
      "Epoch 623/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0901 - jaccard: 0.6852 - val_loss: 0.2525 - val_jaccard: 0.4905\n",
      "Epoch 624/1000\n",
      "255/260 [============================>.] - ETA: 0s - loss: 0.0895 - jaccard: 0.6826\n",
      "Epoch 00623: reducing learning rate to 7.812500371073838e-06.\n",
      "260/260 [==============================] - 22s - loss: 0.0900 - jaccard: 0.6832 - val_loss: 0.2502 - val_jaccard: 0.4919\n",
      "Epoch 625/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0907 - jaccard: 0.6841 - val_loss: 0.2494 - val_jaccard: 0.4918\n",
      "Epoch 626/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0900 - jaccard: 0.6879 - val_loss: 0.2490 - val_jaccard: 0.4916\n",
      "Epoch 627/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0918 - jaccard: 0.6835 - val_loss: 0.2492 - val_jaccard: 0.4911\n",
      "Epoch 628/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0909 - jaccard: 0.6814 - val_loss: 0.2495 - val_jaccard: 0.4913\n",
      "Epoch 629/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0912 - jaccard: 0.6809 - val_loss: 0.2495 - val_jaccard: 0.4914\n",
      "Epoch 630/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0903 - jaccard: 0.6811 - val_loss: 0.2487 - val_jaccard: 0.4923\n",
      "Epoch 631/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0914 - jaccard: 0.6816 - val_loss: 0.2492 - val_jaccard: 0.4924\n",
      "Epoch 632/1000\n",
      "260/260 [==============================] - 21s - loss: 0.0909 - jaccard: 0.6793 - val_loss: 0.2482 - val_jaccard: 0.4918\n",
      "Epoch 00631: early stopping\n",
      "260/260 [==============================] - 3s     \n",
      "This is run # 124 for class 5\n",
      "Train on 260 samples, validate on 64 samples\n",
      "Epoch 1/1000\n",
      "260/260 [==============================] - 20s - loss: 0.7839 - jaccard: 0.2178 - val_loss: 0.7482 - val_jaccard: 0.1914\n",
      "Epoch 2/1000\n",
      "260/260 [==============================] - 20s - loss: 0.7479 - jaccard: 0.2270 - val_loss: 0.7199 - val_jaccard: 0.2030\n",
      "Epoch 3/1000\n",
      "260/260 [==============================] - 21s - loss: 0.7104 - jaccard: 0.2438 - val_loss: 0.6988 - val_jaccard: 0.2117\n",
      "Epoch 4/1000\n",
      "260/260 [==============================] - 21s - loss: 0.7000 - jaccard: 0.2485 - val_loss: 0.6854 - val_jaccard: 0.2172\n",
      "Epoch 5/1000\n",
      "260/260 [==============================] - 21s - loss: 0.6817 - jaccard: 0.2580 - val_loss: 0.6737 - val_jaccard: 0.2223\n",
      "Epoch 6/1000\n",
      "260/260 [==============================] - 21s - loss: 0.6849 - jaccard: 0.2527 - val_loss: 0.6642 - val_jaccard: 0.2265\n",
      "Epoch 7/1000\n",
      "260/260 [==============================] - 21s - loss: 0.6682 - jaccard: 0.2633 - val_loss: 0.6563 - val_jaccard: 0.2304\n",
      "Epoch 8/1000\n",
      "260/260 [==============================] - 21s - loss: 0.6354 - jaccard: 0.2820 - val_loss: 0.6483 - val_jaccard: 0.2343\n",
      "Epoch 9/1000\n",
      "260/260 [==============================] - 21s - loss: 0.6338 - jaccard: 0.2783 - val_loss: 0.6425 - val_jaccard: 0.2372\n",
      "Epoch 10/1000\n",
      "260/260 [==============================] - 22s - loss: 0.6420 - jaccard: 0.2731 - val_loss: 0.6392 - val_jaccard: 0.2393\n",
      "Epoch 11/1000\n",
      "260/260 [==============================] - 22s - loss: 0.6311 - jaccard: 0.2808 - val_loss: 0.6370 - val_jaccard: 0.2406\n",
      "Epoch 12/1000\n",
      "260/260 [==============================] - 22s - loss: 0.6205 - jaccard: 0.2864 - val_loss: 0.6330 - val_jaccard: 0.2427\n",
      "Epoch 13/1000\n",
      "260/260 [==============================] - 22s - loss: 0.6203 - jaccard: 0.2859 - val_loss: 0.6314 - val_jaccard: 0.2440\n",
      "Epoch 14/1000\n",
      "260/260 [==============================] - 22s - loss: 0.6199 - jaccard: 0.2827 - val_loss: 0.6290 - val_jaccard: 0.2454\n",
      "Epoch 15/1000\n",
      "260/260 [==============================] - 22s - loss: 0.6053 - jaccard: 0.2932 - val_loss: 0.6267 - val_jaccard: 0.2466\n",
      "Epoch 16/1000\n",
      "260/260 [==============================] - 21s - loss: 0.6122 - jaccard: 0.2874 - val_loss: 0.6229 - val_jaccard: 0.2486\n",
      "Epoch 17/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5940 - jaccard: 0.3010 - val_loss: 0.6196 - val_jaccard: 0.2503\n",
      "Epoch 18/1000\n",
      "260/260 [==============================] - 22s - loss: 0.6035 - jaccard: 0.2920 - val_loss: 0.6190 - val_jaccard: 0.2509\n",
      "Epoch 19/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5924 - jaccard: 0.2977 - val_loss: 0.6162 - val_jaccard: 0.2524\n",
      "Epoch 20/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5706 - jaccard: 0.3126 - val_loss: 0.6126 - val_jaccard: 0.2543\n",
      "Epoch 21/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5878 - jaccard: 0.3020 - val_loss: 0.6094 - val_jaccard: 0.2558\n",
      "Epoch 22/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5799 - jaccard: 0.3038 - val_loss: 0.6076 - val_jaccard: 0.2567\n",
      "Epoch 23/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5792 - jaccard: 0.3056 - val_loss: 0.6057 - val_jaccard: 0.2576\n",
      "Epoch 24/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5747 - jaccard: 0.3095 - val_loss: 0.6070 - val_jaccard: 0.2572\n",
      "Epoch 25/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5690 - jaccard: 0.3139 - val_loss: 0.6064 - val_jaccard: 0.2577\n",
      "Epoch 26/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5703 - jaccard: 0.3120 - val_loss: 0.6030 - val_jaccard: 0.2592\n",
      "Epoch 27/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5657 - jaccard: 0.3133 - val_loss: 0.6015 - val_jaccard: 0.2601\n",
      "Epoch 28/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5645 - jaccard: 0.3139 - val_loss: 0.6005 - val_jaccard: 0.2608\n",
      "Epoch 29/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5752 - jaccard: 0.3082 - val_loss: 0.5980 - val_jaccard: 0.2621\n",
      "Epoch 30/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5634 - jaccard: 0.3156 - val_loss: 0.5966 - val_jaccard: 0.2624\n",
      "Epoch 31/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5537 - jaccard: 0.3198 - val_loss: 0.5950 - val_jaccard: 0.2634\n",
      "Epoch 32/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5578 - jaccard: 0.3177 - val_loss: 0.5924 - val_jaccard: 0.2649\n",
      "Epoch 33/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5548 - jaccard: 0.3177 - val_loss: 0.5904 - val_jaccard: 0.2658\n",
      "Epoch 34/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5360 - jaccard: 0.3306 - val_loss: 0.5902 - val_jaccard: 0.2659\n",
      "Epoch 35/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5608 - jaccard: 0.3140 - val_loss: 0.5902 - val_jaccard: 0.2656\n",
      "Epoch 36/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5657 - jaccard: 0.3117 - val_loss: 0.5881 - val_jaccard: 0.2667\n",
      "Epoch 37/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5451 - jaccard: 0.3264 - val_loss: 0.5867 - val_jaccard: 0.2677\n",
      "Epoch 38/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5451 - jaccard: 0.3256 - val_loss: 0.5859 - val_jaccard: 0.2683\n",
      "Epoch 39/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5506 - jaccard: 0.3212 - val_loss: 0.5864 - val_jaccard: 0.2681\n",
      "Epoch 40/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5360 - jaccard: 0.3299 - val_loss: 0.5850 - val_jaccard: 0.2687\n",
      "Epoch 41/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5698 - jaccard: 0.3110 - val_loss: 0.5838 - val_jaccard: 0.2691\n",
      "Epoch 42/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5586 - jaccard: 0.3144 - val_loss: 0.5835 - val_jaccard: 0.2695\n",
      "Epoch 43/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5378 - jaccard: 0.3265 - val_loss: 0.5824 - val_jaccard: 0.2699\n",
      "Epoch 44/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5518 - jaccard: 0.3178 - val_loss: 0.5813 - val_jaccard: 0.2704\n",
      "Epoch 45/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5253 - jaccard: 0.3390 - val_loss: 0.5799 - val_jaccard: 0.2709\n",
      "Epoch 46/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5435 - jaccard: 0.3230 - val_loss: 0.5803 - val_jaccard: 0.2709\n",
      "Epoch 47/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5448 - jaccard: 0.3248 - val_loss: 0.5801 - val_jaccard: 0.2713\n",
      "Epoch 48/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5424 - jaccard: 0.3260 - val_loss: 0.5774 - val_jaccard: 0.2722\n",
      "Epoch 49/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5284 - jaccard: 0.3327 - val_loss: 0.5768 - val_jaccard: 0.2726\n",
      "Epoch 50/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5258 - jaccard: 0.3350 - val_loss: 0.5791 - val_jaccard: 0.2721\n",
      "Epoch 51/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5440 - jaccard: 0.3237 - val_loss: 0.5786 - val_jaccard: 0.2724\n",
      "Epoch 52/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5363 - jaccard: 0.3306 - val_loss: 0.5779 - val_jaccard: 0.2726\n",
      "Epoch 53/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5359 - jaccard: 0.3317 - val_loss: 0.5762 - val_jaccard: 0.2735\n",
      "Epoch 54/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5305 - jaccard: 0.3315 - val_loss: 0.5743 - val_jaccard: 0.2744\n",
      "Epoch 55/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5395 - jaccard: 0.3256 - val_loss: 0.5730 - val_jaccard: 0.2751\n",
      "Epoch 56/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5159 - jaccard: 0.3431 - val_loss: 0.5706 - val_jaccard: 0.2759\n",
      "Epoch 57/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5586 - jaccard: 0.3123 - val_loss: 0.5717 - val_jaccard: 0.2756\n",
      "Epoch 58/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5289 - jaccard: 0.3343 - val_loss: 0.5720 - val_jaccard: 0.2755\n",
      "Epoch 59/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5543 - jaccard: 0.3173 - val_loss: 0.5709 - val_jaccard: 0.2759\n",
      "Epoch 60/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5248 - jaccard: 0.3366 - val_loss: 0.5715 - val_jaccard: 0.2760\n",
      "Epoch 61/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5347 - jaccard: 0.3277 - val_loss: 0.5718 - val_jaccard: 0.2760\n",
      "Epoch 62/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5325 - jaccard: 0.3315 - val_loss: 0.5694 - val_jaccard: 0.2770\n",
      "Epoch 63/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5206 - jaccard: 0.3387 - val_loss: 0.5693 - val_jaccard: 0.2770\n",
      "Epoch 64/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5446 - jaccard: 0.3246 - val_loss: 0.5680 - val_jaccard: 0.2775\n",
      "Epoch 65/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5185 - jaccard: 0.3399 - val_loss: 0.5676 - val_jaccard: 0.2777\n",
      "Epoch 66/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5193 - jaccard: 0.3401 - val_loss: 0.5686 - val_jaccard: 0.2774\n",
      "Epoch 67/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5087 - jaccard: 0.3455 - val_loss: 0.5686 - val_jaccard: 0.2775\n",
      "Epoch 68/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5131 - jaccard: 0.3425 - val_loss: 0.5682 - val_jaccard: 0.2779\n",
      "Epoch 69/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5188 - jaccard: 0.3388 - val_loss: 0.5647 - val_jaccard: 0.2795\n",
      "Epoch 70/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5243 - jaccard: 0.3347 - val_loss: 0.5654 - val_jaccard: 0.2792\n",
      "Epoch 71/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5317 - jaccard: 0.3294 - val_loss: 0.5643 - val_jaccard: 0.2798\n",
      "Epoch 72/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5390 - jaccard: 0.3247 - val_loss: 0.5653 - val_jaccard: 0.2792\n",
      "Epoch 73/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5366 - jaccard: 0.3276 - val_loss: 0.5637 - val_jaccard: 0.2801\n",
      "Epoch 74/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5219 - jaccard: 0.3376 - val_loss: 0.5638 - val_jaccard: 0.2802\n",
      "Epoch 75/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5227 - jaccard: 0.3363 - val_loss: 0.5648 - val_jaccard: 0.2800\n",
      "Epoch 76/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5151 - jaccard: 0.3409 - val_loss: 0.5626 - val_jaccard: 0.2808\n",
      "Epoch 77/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5033 - jaccard: 0.3494 - val_loss: 0.5628 - val_jaccard: 0.2807\n",
      "Epoch 78/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5396 - jaccard: 0.3256 - val_loss: 0.5625 - val_jaccard: 0.2812\n",
      "Epoch 79/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5359 - jaccard: 0.3281 - val_loss: 0.5621 - val_jaccard: 0.2811\n",
      "Epoch 80/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5193 - jaccard: 0.3371 - val_loss: 0.5621 - val_jaccard: 0.2811\n",
      "Epoch 81/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5219 - jaccard: 0.3354 - val_loss: 0.5626 - val_jaccard: 0.2812\n",
      "Epoch 82/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5070 - jaccard: 0.3477 - val_loss: 0.5607 - val_jaccard: 0.2820\n",
      "Epoch 83/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5276 - jaccard: 0.3319 - val_loss: 0.5596 - val_jaccard: 0.2824\n",
      "Epoch 84/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5081 - jaccard: 0.3451 - val_loss: 0.5585 - val_jaccard: 0.2829\n",
      "Epoch 85/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5205 - jaccard: 0.3372 - val_loss: 0.5579 - val_jaccard: 0.2832\n",
      "Epoch 86/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5117 - jaccard: 0.3427 - val_loss: 0.5571 - val_jaccard: 0.2837\n",
      "Epoch 87/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4971 - jaccard: 0.3539 - val_loss: 0.5589 - val_jaccard: 0.2826\n",
      "Epoch 88/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5056 - jaccard: 0.3485 - val_loss: 0.5568 - val_jaccard: 0.2835\n",
      "Epoch 89/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5337 - jaccard: 0.3265 - val_loss: 0.5590 - val_jaccard: 0.2826\n",
      "Epoch 90/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5063 - jaccard: 0.3475 - val_loss: 0.5581 - val_jaccard: 0.2831\n",
      "Epoch 91/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4991 - jaccard: 0.3511 - val_loss: 0.5587 - val_jaccard: 0.2828\n",
      "Epoch 92/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5223 - jaccard: 0.3338 - val_loss: 0.5590 - val_jaccard: 0.2830\n",
      "Epoch 93/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5077 - jaccard: 0.3456 - val_loss: 0.5584 - val_jaccard: 0.2835\n",
      "Epoch 94/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4995 - jaccard: 0.3515 - val_loss: 0.5564 - val_jaccard: 0.2841\n",
      "Epoch 95/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5118 - jaccard: 0.3401 - val_loss: 0.5572 - val_jaccard: 0.2837\n",
      "Epoch 96/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5189 - jaccard: 0.3363 - val_loss: 0.5565 - val_jaccard: 0.2839\n",
      "Epoch 97/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4955 - jaccard: 0.3522 - val_loss: 0.5541 - val_jaccard: 0.2850\n",
      "Epoch 98/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5208 - jaccard: 0.3351 - val_loss: 0.5542 - val_jaccard: 0.2850\n",
      "Epoch 99/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4978 - jaccard: 0.3488 - val_loss: 0.5548 - val_jaccard: 0.2849\n",
      "Epoch 100/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4954 - jaccard: 0.3518 - val_loss: 0.5551 - val_jaccard: 0.2848\n",
      "Epoch 101/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5162 - jaccard: 0.3390 - val_loss: 0.5557 - val_jaccard: 0.2842\n",
      "Epoch 102/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5171 - jaccard: 0.3392 - val_loss: 0.5545 - val_jaccard: 0.2851\n",
      "Epoch 103/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5032 - jaccard: 0.3473 - val_loss: 0.5551 - val_jaccard: 0.2848\n",
      "Epoch 104/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5123 - jaccard: 0.3409 - val_loss: 0.5553 - val_jaccard: 0.2845\n",
      "Epoch 105/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5088 - jaccard: 0.3439 - val_loss: 0.5548 - val_jaccard: 0.2848\n",
      "Epoch 106/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4900 - jaccard: 0.3573 - val_loss: 0.5551 - val_jaccard: 0.2848\n",
      "Epoch 107/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5069 - jaccard: 0.3444 - val_loss: 0.5536 - val_jaccard: 0.2857\n",
      "Epoch 108/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5027 - jaccard: 0.3470 - val_loss: 0.5523 - val_jaccard: 0.2864\n",
      "Epoch 109/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5067 - jaccard: 0.3446 - val_loss: 0.5526 - val_jaccard: 0.2863\n",
      "Epoch 110/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5128 - jaccard: 0.3402 - val_loss: 0.5516 - val_jaccard: 0.2868\n",
      "Epoch 111/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4916 - jaccard: 0.3551 - val_loss: 0.5512 - val_jaccard: 0.2870\n",
      "Epoch 112/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5265 - jaccard: 0.3314 - val_loss: 0.5505 - val_jaccard: 0.2875\n",
      "Epoch 113/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5045 - jaccard: 0.3466 - val_loss: 0.5505 - val_jaccard: 0.2872\n",
      "Epoch 114/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5133 - jaccard: 0.3399 - val_loss: 0.5525 - val_jaccard: 0.2863\n",
      "Epoch 115/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4991 - jaccard: 0.3522 - val_loss: 0.5531 - val_jaccard: 0.2860\n",
      "Epoch 116/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5019 - jaccard: 0.3473 - val_loss: 0.5558 - val_jaccard: 0.2846\n",
      "Epoch 117/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4878 - jaccard: 0.3571 - val_loss: 0.5520 - val_jaccard: 0.2864\n",
      "Epoch 118/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5146 - jaccard: 0.3390 - val_loss: 0.5509 - val_jaccard: 0.2871\n",
      "Epoch 119/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5186 - jaccard: 0.3374 - val_loss: 0.5504 - val_jaccard: 0.2874\n",
      "Epoch 120/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4982 - jaccard: 0.3482 - val_loss: 0.5487 - val_jaccard: 0.2882\n",
      "Epoch 121/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5102 - jaccard: 0.3397 - val_loss: 0.5490 - val_jaccard: 0.2880\n",
      "Epoch 122/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5275 - jaccard: 0.3286 - val_loss: 0.5483 - val_jaccard: 0.2884\n",
      "Epoch 123/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5171 - jaccard: 0.3358 - val_loss: 0.5483 - val_jaccard: 0.2882\n",
      "Epoch 124/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5214 - jaccard: 0.3316 - val_loss: 0.5478 - val_jaccard: 0.2882\n",
      "Epoch 125/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4990 - jaccard: 0.3511 - val_loss: 0.5481 - val_jaccard: 0.2880\n",
      "Epoch 126/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5051 - jaccard: 0.3439 - val_loss: 0.5479 - val_jaccard: 0.2885\n",
      "Epoch 127/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5197 - jaccard: 0.3341 - val_loss: 0.5481 - val_jaccard: 0.2880\n",
      "Epoch 128/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5155 - jaccard: 0.3370 - val_loss: 0.5473 - val_jaccard: 0.2886\n",
      "Epoch 129/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4866 - jaccard: 0.3576 - val_loss: 0.5476 - val_jaccard: 0.2886\n",
      "Epoch 130/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4759 - jaccard: 0.3649 - val_loss: 0.5473 - val_jaccard: 0.2889\n",
      "Epoch 131/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5149 - jaccard: 0.3412 - val_loss: 0.5478 - val_jaccard: 0.2888\n",
      "Epoch 132/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4733 - jaccard: 0.3671 - val_loss: 0.5460 - val_jaccard: 0.2897\n",
      "Epoch 133/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5143 - jaccard: 0.3366 - val_loss: 0.5457 - val_jaccard: 0.2896\n",
      "Epoch 134/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4939 - jaccard: 0.3514 - val_loss: 0.5476 - val_jaccard: 0.2889\n",
      "Epoch 135/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5167 - jaccard: 0.3357 - val_loss: 0.5452 - val_jaccard: 0.2898\n",
      "Epoch 136/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5049 - jaccard: 0.3433 - val_loss: 0.5444 - val_jaccard: 0.2902\n",
      "Epoch 137/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4845 - jaccard: 0.3576 - val_loss: 0.5442 - val_jaccard: 0.2901\n",
      "Epoch 138/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4669 - jaccard: 0.3705 - val_loss: 0.5444 - val_jaccard: 0.2901\n",
      "Epoch 139/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4880 - jaccard: 0.3560 - val_loss: 0.5437 - val_jaccard: 0.2908\n",
      "Epoch 140/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4760 - jaccard: 0.3628 - val_loss: 0.5451 - val_jaccard: 0.2901\n",
      "Epoch 141/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4756 - jaccard: 0.3655 - val_loss: 0.5440 - val_jaccard: 0.2904\n",
      "Epoch 142/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4988 - jaccard: 0.3486 - val_loss: 0.5448 - val_jaccard: 0.2902\n",
      "Epoch 143/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5005 - jaccard: 0.3447 - val_loss: 0.5460 - val_jaccard: 0.2897\n",
      "Epoch 144/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4843 - jaccard: 0.3599 - val_loss: 0.5452 - val_jaccard: 0.2902\n",
      "Epoch 145/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4839 - jaccard: 0.3583 - val_loss: 0.5431 - val_jaccard: 0.2911\n",
      "Epoch 146/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5075 - jaccard: 0.3415 - val_loss: 0.5438 - val_jaccard: 0.2908\n",
      "Epoch 147/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4879 - jaccard: 0.3562 - val_loss: 0.5441 - val_jaccard: 0.2904\n",
      "Epoch 148/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4797 - jaccard: 0.3618 - val_loss: 0.5443 - val_jaccard: 0.2906\n",
      "Epoch 149/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4788 - jaccard: 0.3623 - val_loss: 0.5445 - val_jaccard: 0.2902\n",
      "Epoch 150/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5081 - jaccard: 0.3405 - val_loss: 0.5447 - val_jaccard: 0.2902\n",
      "Epoch 151/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4973 - jaccard: 0.3486 - val_loss: 0.5438 - val_jaccard: 0.2902\n",
      "Epoch 152/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5010 - jaccard: 0.3448 - val_loss: 0.5435 - val_jaccard: 0.2906\n",
      "Epoch 153/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4696 - jaccard: 0.3669 - val_loss: 0.5441 - val_jaccard: 0.2903\n",
      "Epoch 154/1000\n",
      "260/260 [==============================] - 22s - loss: 0.5030 - jaccard: 0.3438 - val_loss: 0.5450 - val_jaccard: 0.2900\n",
      "Epoch 155/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5050 - jaccard: 0.3437 - val_loss: 0.5445 - val_jaccard: 0.2907\n",
      "Epoch 156/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5144 - jaccard: 0.3358 - val_loss: 0.5447 - val_jaccard: 0.2900\n",
      "Epoch 157/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5009 - jaccard: 0.3472 - val_loss: 0.5413 - val_jaccard: 0.2916\n",
      "Epoch 158/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4755 - jaccard: 0.3628 - val_loss: 0.5418 - val_jaccard: 0.2911\n",
      "Epoch 159/1000\n",
      "255/260 [============================>.] - ETA: 0s - loss: 0.4994 - jaccard: 0.3456\n",
      "Epoch 00158: reducing learning rate to 3.906250185536919e-06.\n",
      "260/260 [==============================] - 21s - loss: 0.4986 - jaccard: 0.3455 - val_loss: 0.5412 - val_jaccard: 0.2916\n",
      "Epoch 160/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4777 - jaccard: 0.3615 - val_loss: 0.5415 - val_jaccard: 0.2915\n",
      "Epoch 161/1000\n",
      "260/260 [==============================] - 22s - loss: 0.4788 - jaccard: 0.3606 - val_loss: 0.5406 - val_jaccard: 0.2917\n",
      "Epoch 162/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4952 - jaccard: 0.3495 - val_loss: 0.5398 - val_jaccard: 0.2923\n",
      "Epoch 163/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4916 - jaccard: 0.3520 - val_loss: 0.5385 - val_jaccard: 0.2930\n",
      "Epoch 164/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4782 - jaccard: 0.3607 - val_loss: 0.5385 - val_jaccard: 0.2929\n",
      "Epoch 165/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4838 - jaccard: 0.3574 - val_loss: 0.5391 - val_jaccard: 0.2926\n",
      "Epoch 166/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4757 - jaccard: 0.3609 - val_loss: 0.5383 - val_jaccard: 0.2928\n",
      "Epoch 167/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4964 - jaccard: 0.3475 - val_loss: 0.5385 - val_jaccard: 0.2929\n",
      "Epoch 168/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4967 - jaccard: 0.3462 - val_loss: 0.5383 - val_jaccard: 0.2929\n",
      "Epoch 169/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4770 - jaccard: 0.3605 - val_loss: 0.5383 - val_jaccard: 0.2928\n",
      "Epoch 170/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4940 - jaccard: 0.3497 - val_loss: 0.5384 - val_jaccard: 0.2929\n",
      "Epoch 171/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5032 - jaccard: 0.3408 - val_loss: 0.5383 - val_jaccard: 0.2931\n",
      "Epoch 172/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4737 - jaccard: 0.3637 - val_loss: 0.5380 - val_jaccard: 0.2931\n",
      "Epoch 173/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4732 - jaccard: 0.3626 - val_loss: 0.5384 - val_jaccard: 0.2929\n",
      "Epoch 174/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4780 - jaccard: 0.3620 - val_loss: 0.5378 - val_jaccard: 0.2933\n",
      "Epoch 175/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4752 - jaccard: 0.3617 - val_loss: 0.5375 - val_jaccard: 0.2933\n",
      "Epoch 176/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4677 - jaccard: 0.3683 - val_loss: 0.5378 - val_jaccard: 0.2933\n",
      "Epoch 177/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4760 - jaccard: 0.3628 - val_loss: 0.5379 - val_jaccard: 0.2932\n",
      "Epoch 178/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4924 - jaccard: 0.3486 - val_loss: 0.5367 - val_jaccard: 0.2937\n",
      "Epoch 179/1000\n",
      "260/260 [==============================] - 21s - loss: 0.5104 - jaccard: 0.3370 - val_loss: 0.5372 - val_jaccard: 0.2934\n",
      "Epoch 180/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4766 - jaccard: 0.3603 - val_loss: 0.5373 - val_jaccard: 0.2933\n",
      "Epoch 181/1000\n",
      "255/260 [============================>.] - ETA: 0s - loss: 0.4871 - jaccard: 0.3559\n",
      "Epoch 00180: reducing learning rate to 1.9531250927684596e-06.\n",
      "260/260 [==============================] - 21s - loss: 0.4881 - jaccard: 0.3535 - val_loss: 0.5372 - val_jaccard: 0.2933\n",
      "Epoch 182/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4936 - jaccard: 0.3497 - val_loss: 0.5376 - val_jaccard: 0.2932\n",
      "Epoch 183/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4673 - jaccard: 0.3673 - val_loss: 0.5379 - val_jaccard: 0.2932\n",
      "Epoch 184/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4816 - jaccard: 0.3582 - val_loss: 0.5380 - val_jaccard: 0.2932\n",
      "Epoch 185/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4897 - jaccard: 0.3514 - val_loss: 0.5380 - val_jaccard: 0.2932\n",
      "Epoch 186/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4798 - jaccard: 0.3598 - val_loss: 0.5385 - val_jaccard: 0.2930\n",
      "Epoch 187/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4952 - jaccard: 0.3476 - val_loss: 0.5383 - val_jaccard: 0.2931\n",
      "Epoch 188/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4924 - jaccard: 0.3499 - val_loss: 0.5381 - val_jaccard: 0.2932\n",
      "Epoch 189/1000\n",
      "260/260 [==============================] - 21s - loss: 0.4853 - jaccard: 0.3537 - val_loss: 0.5377 - val_jaccard: 0.2934\n",
      "Epoch 00188: early stopping\n",
      "260/260 [==============================] - 3s     \n"
     ]
    }
   ],
   "source": [
    "def trainer(model,class_,nb_epochs=1000,fit=True,use_existing=False):\n",
    "    print('This is run # {} for class {}'.format(run,class_))\n",
    "    \n",
    "    if use_existing:\n",
    "        model.load_weights('./data/weights/model_weights_class_{}_run_{}.hdf5'.format(class_,run))\n",
    "        \n",
    "    if fit:\n",
    "        quitter = EarlyStopping(monitor='loss', min_delta=0.001, patience=50, verbose=1, mode='auto')\n",
    "        lrreducer = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=20, verbose=1, mode='auto', epsilon=0.001, cooldown=2, min_lr=0)\n",
    "        model_checkpoint = ModelCheckpoint('./data/weights/model_weights_class_{}_run_{}.hdf5'.format(class_,run), monitor='loss', save_best_only=True)\n",
    "        csvlogger = CSVLogger('./data/logs/training_log_class_{}_run_{}'.format(class_,run), separator=',', append=True)\n",
    "        # tensorboard = TensorBoard(log_dir='./data/logs/'+'tensorboard_all-classes-run_{:04d}'.format(run), histogram_freq=0, write_graph=True, write_images=False)\n",
    "        # tensorboard --logdir=data/logs\n",
    "        \n",
    "        model.fit(x_train, y_train[:,class_:class_+1,:,:],\n",
    "                  batch_size=5,\n",
    "                  nb_epoch=nb_epochs,\n",
    "                  verbose=1,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[model_checkpoint,csvlogger,quitter,lrreducer],\n",
    "                  validation_data=(x_test,y_test[:,class_:class_+1,:,:]),\n",
    "                  initial_epoch=0)\n",
    "            \n",
    "    preds = model.predict(x_train, verbose=1)\n",
    "    np.save('./data/predictions/predictions_run_{}_class_{}.npy'.format(run,class_), preds)\n",
    "    \n",
    "    return model\n",
    "\n",
    "for class_ in range(4,6):\n",
    "    model.load_weights('./data/misc/initial_weights.hdf5')\n",
    "    model = trainer(model,class_,fit=True,use_existing=False)\n",
    "    model.save('./data/models/u-net-complete-model-run_{}_class_{}.hdf5'.format(run,class_))\n",
    "    push('Training on class {} is done'.format(class_),\n",
    "     'Train loss: %f, train jaccard: %f, val loss %f, val jaccard%f' %(model.history.history['loss'][-1],model.history.history['jaccard'][-1],model.history.history['val_loss'][-1],model.history.history['val_jaccard'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import io\n",
    "import tifffile as tiff\n",
    "import zipfile\n",
    "\n",
    "import skimage.transform\n",
    "import shapely.wkt # shapely.wkt.loads()\n",
    "import shapely.geometry \n",
    "import cv2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Specify that this notebook should only use the CPU\n",
    "# This avoids memory problems if the model is running on the GPU elsewhere\n",
    "# Note: do not try to train / predict as this will likely be very slow\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=cpu\"\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, merge, Activation, Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Cropping2D, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "K.set_image_dim_ordering('th')  # Theano dimension ordering in this code\n",
    "# \"tf\" assumes (rows, cols, channels) while \"th\" assumes (channels, rows, cols)\n",
    "# Possibly change this around natively in the data so the backend doesn't have to switch them\n",
    "# Only necessary if I use TF!\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pushbullet import Pushbullet\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('./data/sample_submission.csv',names=['imageID','feature','wkt'],skiprows=1)\n",
    "grid_sizes = pd.read_csv('./data/grid_sizes.csv',names=['imageID','xmax','ymin'],skiprows=1)\n",
    "\n",
    "class_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_imgs = np.load('./data/submission_images_processed.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard(y_true, y_pred,smooth=1.):\n",
    "        y_true_f = K.flatten(y_true)\n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n",
    "    \n",
    "model = load_model('u-net-complete-model-run_88-class_2.h5',custom_objects={'jaccard': jaccard})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_polygons(msk, epsilon=5, min_area=1.):\n",
    "    # first, find contours with cv2: it's much faster than shapely\n",
    "    # cv2.RETR_CCOMP specifies that there are only two hierarchies: external and internal\n",
    "    contours, hierarchy = cv2.findContours(((msk == 1) * 255).astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)[1:]\n",
    "    \n",
    "    # create approximate contours to have reasonable submission size\n",
    "    approx_contours = [cv2.approxPolyDP(cnt, epsilon, True) for cnt in contours]\n",
    "    \n",
    "    if not contours:\n",
    "        return shapely.geometry.MultiPolygon()\n",
    "    \n",
    "    # now messy stuff to associate parent and child contours\n",
    "    # defaultdict creates an emptylist if it's called on a key that doesn't exist\n",
    "    cnt_children = defaultdict(list)\n",
    "    \n",
    "    # Creates an empty set, which is an unordered collection\n",
    "    child_contours = set()\n",
    "    \n",
    "    # Tests if hierarchy has shape 1 in the first dimension\n",
    "    # Should throw an error if it is not 1, i.e. we expect it to be 1\n",
    "    assert hierarchy.shape[0] == 1\n",
    "    \n",
    "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    # The hierarchy is an array of (4,) elements like this: [Next, Previous, First_Child, Parent]\n",
    "    # Hierarchy should have shape (1, X, 4) thus hierarchy[0] just grabs the all of hierarchy arrays\n",
    "    # We then grab the Parents value and the contour's position (from enumerate) for each contour\n",
    "    for idx, parent_idx in enumerate(hierarchy[0][:,3]):\n",
    "        # If the parent_id != -1, this means there is a parent, thus this hiearchy is a child\n",
    "        if parent_idx != -1:\n",
    "            # Add the id of that contour to the child contours set\n",
    "            child_contours.add(idx)\n",
    "            # Add a key:value to the cnt_children dict, \n",
    "            # The key is the contour id, and the value is a list containing the child contour\n",
    "            cnt_children[parent_idx].append(approx_contours[idx])\n",
    "    \n",
    "    # Ultimately, the child polygons must be filled with 0 so that they are empty...\n",
    "    # Thus have a dict of child contours (with their corresponding parent ID) is helpful\n",
    "    \n",
    "    # create actual polygons filtering by area (removes artifacts)\n",
    "    all_polygons = []\n",
    "    # For each contour...\n",
    "    for idx, cnt in enumerate(approx_contours):\n",
    "        # First check that the contour is not a child\n",
    "        # And determine that it's area is larger than some minimum we can define\n",
    "        # min_area is set to 1 for now\n",
    "        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n",
    "            # Check that the second dimension of the contour is 1\n",
    "            assert cnt.shape[1] == 1\n",
    "            \n",
    "            # Make a shapely polygon object\n",
    "            # supply shell and holes\n",
    "            # Shells are the contours that passed the if test above (i.e. NOT children)\n",
    "            # Holes are all of the children that are stored in the cnt_children dict\n",
    "            # The list comprehension grabs each contour from the dict matching the ID of this polygon and checks it's size is above the minimum\n",
    "            poly = shapely.geometry.Polygon(shell=cnt[:, 0, :],\n",
    "                                            holes=[c[:, 0, :] for c in cnt_children.get(idx, []) if cv2.contourArea(c) >= min_area])\n",
    "            \n",
    "            # Finally, we append this polygon to the running list\n",
    "            all_polygons.append(poly)\n",
    "            \n",
    "    # approximating polygons might have created invalid ones, fix them\n",
    "    all_polygons = shapely.geometry.MultiPolygon(all_polygons)\n",
    "    \n",
    "    # The is_valid() method from shapely returns true if the polygon is valid\n",
    "    if not all_polygons.is_valid:\n",
    "        # From http://toblerity.org/shapely/shapely.geometry.html#module-shapely.geometry.multipolygon\n",
    "        # A zero distance may be used to “tidy” a polygon\n",
    "        all_polygons = all_polygons.buffer(0)\n",
    "        \n",
    "        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n",
    "        # need to keep it a Multi throughout\n",
    "        if all_polygons.type == 'Polygon':\n",
    "            all_polygons = MultiPolygon([all_polygons])\n",
    "    return all_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictor():\n",
    "    if os.path.exists('./data/submisison_wkts.npy'):\n",
    "        wkts = np.load('./data/submisison_wkts.npy').item()\n",
    "    else:\n",
    "        wkts = {}\n",
    "\n",
    "    msks = {}\n",
    "    for imageID in sorted(unique(sample.imageID)):\n",
    "        img = test_imgs[imageID]\n",
    "        msk = model.predict(img)\n",
    "        msks[imageID] = msk\n",
    "        img_h, img_w = img.shape[1], img.shape[2]\n",
    "\n",
    "        # Threshold the mask\n",
    "        msk[msk>=threshold] = 1\n",
    "        msk[msk<threshold] = 0\n",
    "\n",
    "        # Make polygons\n",
    "        polygons = mask_to_polygons(msk)\n",
    "\n",
    "        # Scale polygons\n",
    "        # Double check this...\n",
    "        xmax, ymin = grid_sizes[grid_sizes.imageID == imageID].iloc[0, 1:].astype(float)\n",
    "        xfact = xmax / (img_w * (img_w / (img_w + 1)))\n",
    "        yfact = ymin / (img_h * (img_h / (img_h + 1)))\n",
    "\n",
    "        polygons = shapely.affinity.scale(polygons, xfact=xfact, yfact=yfact, origin=(0, 0, 0))\n",
    "\n",
    "        # Make WKTs\n",
    "        wkt = shapely.wkt.dumps(polygons)\n",
    "\n",
    "        wkts[imageID] = {class_:wkt}\n",
    "\n",
    "    np.save('./data/submisison_msks.npy',msks)\n",
    "    np.save('./data/submisison_wkts.npy', wkts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

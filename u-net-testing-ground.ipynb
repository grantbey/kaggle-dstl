{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes and thoughts\n",
    "\n",
    "#### Current best ideas / runs that work / etc.\n",
    "- Batch size = ~1/6th of training data size seems to make all the difference\n",
    "- nfilters is only 4 for a single class (perhaps 8 works better? Takes longer to train. Trade-offs...)\n",
    "- Perhaps the best method is to train 10 models, one for each class\n",
    "- Dropout after each maxpooling step in the down-path and after each upconv/conv/conv step in the up-path. I used p=0.2 for each dropout layer, however the code is written such that this can be changed ona  per-layer basis.\n",
    "- Activation = LeakyReLu\n",
    "- Batchnorm is *after* the activation\n",
    "- L2 reg is applied to each convolution with a lambda of 0.00001. Question remains: is this even doing anything?\n",
    "- lr is 0.001. This is the default for Adam. Would a higher value train faster?\n",
    "- Currently there are 400 training images\n",
    "    - Could this be reduced?\n",
    "    - Currently the data augmentation is applied to the entire data set, then it is randomly split for validation\n",
    "    - Should the test/val sets be split early and *then* apply data augmentation *seperately*?\n",
    "    - **NB** be aware that some classes only have a single image. Thus, the training/val sets should each contain examples of this class but it should be heavily augmented so as to be treated as different)\n",
    "\n",
    "#### Ideas\n",
    "- Weight map: sum the total area of all classes in y, then calculate each class' proportion of the total and use `1-value` in place of 1 in the binary mask. This will cause low frequency classes to contribute more to the total loss, i.e. penalizing the model when it fails to predict low frequency classes.\n",
    "\n",
    "#### Data augmentation / image manipulation\n",
    "- [Histogram Equalization](http://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_equalize.html#sphx-glr-auto-examples-color-exposure-plot-equalize-py) (also see [here](https://www.kaggle.com/gabrielaltay/dstl-satellite-imagery-feature-detection/exploring-color-scaling-images/discussion), [here](http://adilmoujahid.com/posts/2016/06/introduction-deep-learning-python-caffe/) and [here](https://medium.com/@vivek.yadav/improved-performance-of-deep-learning-neural-network-models-on-traffic-sign-classification-using-6355346da2dc#.x9nidcsh6))\n",
    "- Rotation (with reflection): see data-augmentation.ipynb\n",
    "- Image normalization: see image-preprocessing-new.ipynb\n",
    "\n",
    "#### Overfitting solutions\n",
    "- CNNs are supposed to be more robust to this because of the shared weight matrix of each filter\n",
    "- **Data augmentation!**\n",
    "    - Have done random rotations on data increasing total n by 6-fold\n",
    "    - Not seeing drastic improvements\n",
    "- L2 regularization (added into the layers via `W_regularizer=l2(l=0.01)` parameter)\n",
    "    - Not seeing much improvement\n",
    "    - Currently set to 0.00001\n",
    "- Move batchnorm to *before* the relu takes place (see [here](http://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras)\n",
    "- Add batchnorm to upconv() layer\n",
    "- Try mode=1 in batchnorm\n",
    "- Dropout hurts the model in my experience..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### U-Net architecture\n",
    "\n",
    "See [here](https://github.com/jocicmarko/ultrasound-nerve-segmentation/blob/master/train.py#L19) for code and [here](https://arxiv.org/pdf/1505.04597.pdf) for the original literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Activation, Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Cropping2D, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adadelta, Adam\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "K.set_image_dim_ordering('th')  # Theano dimension ordering in this code\n",
    "# \"tf\" assumes (rows, cols, channels) while \"th\" assumes (channels, rows, cols)\n",
    "# Possibly change this around natively in the data so the backend doesn't have to switch them\n",
    "# Only necessary if I use TF!\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_preds(preds):\n",
    "    for i in range(preds.shape[0]):\n",
    "        preds[i,0,:,:] = (preds[i,0,:,:].min() - preds[i,0,:,:])/(preds[i,0,:,:].min()-preds[i,0,:,:].max())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_all(i,classType):\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    ax1.imshow(preds[i,0,...],cmap='spectral')\n",
    "\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax2.imshow(np.rint(preds[i,0,...]),cmap='spectral')\n",
    "\n",
    "    ax3 = fig.add_subplot(223)\n",
    "    ax3.imshow(x[i,17,...],cmap='Greys')\n",
    "\n",
    "    ax4 = fig.add_subplot(224)\n",
    "    ax4.imshow(y_oneclass[i,classType,:,:],cmap='spectral')\n",
    "    \n",
    "    plt.show()\n",
    "#plot_all(2,2,classType,0.5)\n",
    "#push('PICTURES!','The plots are ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the components of the pushbullet API\n",
    "from pushbullet import Pushbullet\n",
    "\n",
    "pb = Pushbullet('o.YFPNNPfGRekivaCGHa4qMSgjZt8zJ6FL')\n",
    "phone = pb.devices[0]\n",
    "\n",
    "# Run this cell after anything you want to be notified about!\n",
    "def push(title='Done!',text='Whatever it was, it\\'s done'):\n",
    "    phone.push_note(title,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the training data\n",
    "def import_data():\n",
    "    x = np.load('./data/x_augmented.npy','r')\n",
    "    y = np.load('./data/y_augmented.npy','r')\n",
    "    \n",
    "    '''with open('./data/x_resized_array.pickle','rb') as f:\n",
    "        x = pickle.load(f)\n",
    "        x = x.astype(np.float32)\n",
    "        \n",
    "    with open('./data/y_resized_raster.pickle','rb') as f:\n",
    "        y = pickle.load(f)\n",
    "        y = y.astype(np.float32)'''\n",
    "    \n",
    "    y_oneclass = y[:,3:4,...]\n",
    "    \n",
    "    '''\n",
    "    Classes:\n",
    "    0 Buildings - large building, residential, non-residential, fuel storage facility, fortified building\n",
    "    1 Misc. Manmade structures \n",
    "    2 Road \n",
    "    3 Track - poor/dirt/cart track, footpath/trail\n",
    "    4 Trees - woodland, hedgerows, groups of trees, standalone trees\n",
    "    5 Crops - contour ploughing/cropland, grain (wheat) crops, row (potatoes, turnips) crops\n",
    "    6 Waterway \n",
    "    7 Standing water\n",
    "    8 Vehicle Large - large vehicle (e.g. lorry, truck,bus), logistics vehicle\n",
    "    9 Vehicle Small - small vehicle (car, van), motorbike\n",
    "    '''\n",
    "    \n",
    "    return x, y, y_oneclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y, y_oneclass = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.68 s, sys: 32.8 ms, total: 1.71 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "V2.0 U-Net with batchnorm\n",
    "'''\n",
    "def builder(img_rows = x.shape[2],img_cols = x.shape[3],\n",
    "            nfilters = 32,activation = 'relu',init = 'he_normal',\n",
    "            lr=1.0,decay=0.0,momentum=0.0, nesterov=False,reg=0.01,p=[0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2]):\n",
    "    \n",
    "    def jaccard(y_true, y_pred,smooth=1.):\n",
    "        y_true_f = K.flatten(y_true)\n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n",
    "    \n",
    "    def Conv2DReluBatchNorm(n_filter, w_filter, h_filter, inputs, activation, init='he_uniform',dropout=0.2):\n",
    "        # Batch norm after activation\n",
    "        return BatchNormalization(mode=2, axis=1)(LeakyReLU()((Convolution2D(n_filter, w_filter, h_filter, border_mode='same',init=init,W_regularizer=l2(reg),W_constraint = maxnorm(3))(inputs))))\n",
    "        \n",
    "        # Batch norm before activation\n",
    "        #return LeakyReLU()(BatchNormalization(mode=0, axis=1)((Convolution2D(n_filter, w_filter, h_filter, border_mode='same',init=init,W_regularizer=l2(reg),W_constraint = maxnorm(3))(inputs))))\n",
    "\n",
    "    def up_conv(nfilters,filter_factor,inputs,init=init,activation=activation):\n",
    "        # No batch norm\n",
    "        #return LeakyReLU()(Convolution2D(nfilters*filter_factor, 2, 2, border_mode='same',init=init,W_regularizer=l2(reg),W_constraint = maxnorm(3))(UpSampling2D(size=(2, 2))(inputs)))\n",
    "        \n",
    "        # Batch norm after activation\n",
    "        return BatchNormalization(mode=2, axis=1)(LeakyReLU()(Convolution2D(nfilters*filter_factor, 2, 2, border_mode='same',init=init,W_regularizer=l2(reg),W_constraint = maxnorm(3))(UpSampling2D(size=(2, 2))(inputs))))\n",
    "\n",
    "    inputs = Input((20, img_rows, img_cols))\n",
    "    padded = ZeroPadding2D(padding=(12,12))(inputs)\n",
    "    \n",
    "    conv1 = Conv2DReluBatchNorm(nfilters, 3, 3, padded, activation=activation,init=init)\n",
    "    conv1 = Conv2DReluBatchNorm(nfilters, 3, 3, conv1, activation=activation,init=init)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(p=p[0])(pool1)\n",
    "\n",
    "    conv2 = Conv2DReluBatchNorm(nfilters*2, 3, 3, pool1, activation=activation,init=init)\n",
    "    conv2 = Conv2DReluBatchNorm(nfilters*2, 3, 3, conv2, activation=activation,init=init)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(p=p[1])(pool2)\n",
    "\n",
    "    conv3 = Conv2DReluBatchNorm(nfilters*4, 3, 3, pool2, activation=activation,init=init)\n",
    "    conv3 = Conv2DReluBatchNorm(nfilters*4, 3, 3, conv3, activation=activation,init=init)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(p=p[2])(pool3)\n",
    "\n",
    "    conv4 = Conv2DReluBatchNorm(nfilters*8, 3, 3, pool3, activation=activation,init=init)\n",
    "    conv4 = Conv2DReluBatchNorm(nfilters*8, 3, 3, conv4, activation=activation,init=init)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(p=p[3])(pool4)\n",
    "\n",
    "    conv5 = Conv2DReluBatchNorm(nfilters*16, 3, 3, pool4, activation=activation,init=init)\n",
    "    conv5 = Conv2DReluBatchNorm(nfilters*16, 3, 3, conv5, activation=activation,init=init)\n",
    "    conv5 = Dropout(p=p[4])(conv5)\n",
    "        \n",
    "    up6 = merge([up_conv(nfilters,8,conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = Conv2DReluBatchNorm(nfilters*8, 3, 3, up6, activation=activation,init=init)\n",
    "    conv6 = Conv2DReluBatchNorm(nfilters*8, 3, 3, conv6, activation=activation,init=init)\n",
    "    conv6 = Dropout(p=p[5])(conv6)\n",
    "\n",
    "    up7 = merge([up_conv(nfilters,4,conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = Conv2DReluBatchNorm(nfilters*4, 3, 3, up7, activation=activation,init=init)\n",
    "    conv7 = Conv2DReluBatchNorm(nfilters*4, 3, 3, conv7, activation=activation,init=init)\n",
    "    conv7 = Dropout(p=p[6])(conv7)\n",
    "\n",
    "    up8 = merge([up_conv(nfilters,2,conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = Conv2DReluBatchNorm(nfilters*2, 3, 3, up8, activation=activation,init=init)\n",
    "    conv8 = Conv2DReluBatchNorm(nfilters*2, 3, 3, conv8, activation=activation,init=init)\n",
    "    conv8 = Dropout(p=p[7])(conv8)\n",
    "\n",
    "    up9 = merge([up_conv(nfilters,1,conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = Conv2DReluBatchNorm(nfilters, 3, 3, up9, activation=activation,init=init)\n",
    "    conv9 = Conv2DReluBatchNorm(nfilters, 3, 3, conv9, activation=activation,init=init)\n",
    "    conv9 = Dropout(p=p[8])(conv9)\n",
    "    \n",
    "    conv10 = Conv2DReluBatchNorm(1, 1, 1, conv9, activation='relu',init=init)\n",
    "    cropped = Cropping2D(cropping=((12,12), (12,12)))(conv10)\n",
    "    output = Activation(activation='sigmoid')(cropped)\n",
    "    \n",
    "    model = Model(input=inputs, output=output)\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=lr,decay=decay), loss='binary_crossentropy', metrics=[jaccard])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = builder(img_rows=x.shape[2],img_cols=x.shape[3],\n",
    "            nfilters=4,activation='relu',init='he_normal',\n",
    "            lr=0.001,decay=0,momentum=0,reg=0.00001,p=[0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2])\n",
    "\n",
    "#push('The model is compiled','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is run number: 81...\n",
      "Fitting model...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "run += 1\n",
    "def train_and_predict(model,fit=True,use_existing=False):\n",
    "    print('This is run number: '+ str(run) + '...')\n",
    "    \n",
    "    if use_existing:\n",
    "        model.load_weights('./data/model_weights_class_3_run_'+str(run)+'.hdf5')\n",
    "        \n",
    "    if fit:\n",
    "        \n",
    "        print('Fitting model...')\n",
    "        print('-'*30)\n",
    "        \n",
    "        quitter = EarlyStopping(monitor='loss', min_delta=0.001, patience=100, verbose=1, mode='auto')\n",
    "        lrreducer = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=10, verbose=1, mode='auto', epsilon=0.001, cooldown=2, min_lr=0)\n",
    "        model_checkpoint = ModelCheckpoint('./data/model_weights_class_3_run_'+str(run)+'.hdf5', monitor='loss', save_best_only=True)\n",
    "        csvlogger = CSVLogger('./data/training_log_run_'+str(run), separator=',', append=False)\n",
    "\n",
    "        #tensorboard = TensorBoard(log_dir='./logs/'+'run_'+str(run), histogram_freq=0, write_graph=True, write_images=False)\n",
    "        '''\n",
    "        screen -S tensorboard\n",
    "        tensorboard --logdir=logs\n",
    "        <ctrl + a,d to exit>\n",
    "        screen -r tensorboard\n",
    "        '''\n",
    "        \n",
    "        model.fit(x, y_oneclass,\n",
    "                  batch_size=40,\n",
    "                  nb_epoch=1000,\n",
    "                  verbose=1,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[model_checkpoint,csvlogger],\n",
    "                  validation_split=0.2,\n",
    "                  initial_epoch=0)\n",
    "    \n",
    "        print('Predicting masks on test data...')\n",
    "        print('-'*30)\n",
    "        \n",
    "    imgs_mask_test = model.predict(x, verbose=1)\n",
    "    np.save('jaccard_preds_all_data.npy', imgs_mask_test)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = train_and_predict(model,fit=True,use_existing=False)\n",
    "push('Training is done',\n",
    "     'Train loss: %f, train jaccard: %f, val loss %f, val jaccard%f' %(model.history.history['loss'][-1],model.history.history['jaccard'][-1],model.history.history['val_loss'][-1],model.history.history['val_jaccard'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = np.load('jaccard_preds_all_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(x[120:150,...],y_oneclass[120:150,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = False\n",
    "if norm:\n",
    "    preds = norm_preds(preds)\n",
    "i = np.random.choice(range(120),1)[0]\n",
    "print(i)\n",
    "plot_all(i,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_everything():\n",
    "    fig = plt.figure(figsize=(12,36))\n",
    "    #num = np.random.randint(10,25,10)\n",
    "    num = np.arange(0,10)\n",
    "    for i in range(1,10):\n",
    "        ax1 = fig.add_subplot(10,8,8*i-7)\n",
    "        ax1.imshow(preds[num[i],0,...],cmap='spectral')\n",
    "        \n",
    "        ax2 = fig.add_subplot(10,8,8*i-6)\n",
    "        ax2.imshow(y_oneclass[num[i],0,...],cmap='spectral')\n",
    "        \n",
    "        ax3 = fig.add_subplot(10,8,8*i-5)\n",
    "        ax3.imshow(preds[num[i],1,...],cmap='spectral')\n",
    "        \n",
    "        ax4 = fig.add_subplot(10,8,8*i-4)\n",
    "        ax4.imshow(y_oneclass[num[i],1,...],cmap='spectral')\n",
    "        \n",
    "        ax5 = fig.add_subplot(10,8,8*i-3)\n",
    "        ax5.imshow(preds[num[i],2,...],cmap='spectral')\n",
    "        \n",
    "        ax6 = fig.add_subplot(10,8,8*i-2)\n",
    "        ax6.imshow(y_oneclass[num[i],2,...],cmap='spectral')\n",
    "        \n",
    "        ax7 = fig.add_subplot(10,8,8*i-1)\n",
    "        ax7.imshow(preds[num[i],3,...],cmap='spectral')\n",
    "        \n",
    "        ax8 = fig.add_subplot(10,8,8*i)\n",
    "        ax8.imshow(y_oneclass[num[i],3,...],cmap='spectral')\n",
    "        \n",
    "    plt.show()\n",
    "plot_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_classifier(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defunct bits and pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_cancelled(model):\n",
    "    model.load_weights('./data/model_weights_class_3_run_66.hdf5')\n",
    "    imgs_mask_test = model.predict(x, verbose=1)\n",
    "    return imgs_mask_test\n",
    "\n",
    "preds = load_cancelled(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_classifier(model):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(model.history.history['loss'], \"-\",color='blue',label=\"Training final loss: \"+str(round(model.history.history['loss'][-1],4)))\n",
    "    ax.plot(model.history.history['jaccard'], \"-\",color='orange',label=\"testing final loss: \"+str(round(model.history.history['jaccard'][-1],4)))\n",
    "    #ax.set_xlim([0, epochs])\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Jaccard / Loss')\n",
    "    plt.legend(loc='best')\n",
    "    ax.set_title('Metrics vs time (epochs)')\n",
    "    \n",
    "    '''ax = fig.add_subplot(122)\n",
    "    ax.plot(model.history['acc'], \"-\",color='blue',label=\"Training final acc: \"+str(round(model.history['acc'][-1],4)))\n",
    "    ax.plot(model.history['val_acc'], \"-\",color='orange',label=\"testing final acc: \"+str(round(model.history['val_acc'][-1],4)))\n",
    "    #ax.set_xlim([0, epochs])\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    ax.set_title('Accuracy vs time (epochs)')    \n",
    "    '''\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the training data\n",
    "def import_data(load_whitened = False, normalize = True):\n",
    "    if load_whitened:\n",
    "        with open('./data/x_whitened_resized_array.pickle','rb') as f:\n",
    "            x = pickle.load(f)\n",
    "            x = x.astype('float32')\n",
    "    else:\n",
    "        with open('./data/x_resized_array.pickle','rb') as f:\n",
    "            x = pickle.load(f)\n",
    "            x = x.astype('float32')\n",
    "            # Normalize data to max values\n",
    "            for i in range(x.shape[0]):\n",
    "                for j in range(x.shape[1]):\n",
    "                    x[i,j,:,:] *= 1/x[i,j,:,:].max()\n",
    "                    \n",
    "    # Normalize values between 1 and 0\n",
    "    if normalize:\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                #x[i,j,:,:] /= x[i,j,:,:].max()\n",
    "                x[i,j,:,:] = (x[i,j,:,:].min() - x[i,j,:,:])/(x[i,j,:,:].min() - x[i,j,:,:].max())\n",
    "\n",
    "    with open('./data/y_resized_raster.pickle','rb') as f:\n",
    "        y = pickle.load(f)\n",
    "        y = y.astype(np.float32)\n",
    "        \n",
    "    y_oneclass = y[:,1:6,...]\n",
    "    \n",
    "    '''\n",
    "    Classes:\n",
    "    0 Buildings - large building, residential, non-residential, fuel storage facility, fortified building\n",
    "    1 Misc. Manmade structures \n",
    "    2 Road \n",
    "    3 Track - poor/dirt/cart track, footpath/trail\n",
    "    4 Trees - woodland, hedgerows, groups of trees, standalone trees\n",
    "    5 Crops - contour ploughing/cropland, grain (wheat) crops, row (potatoes, turnips) crops\n",
    "    6 Waterway \n",
    "    7 Standing water\n",
    "    8 Vehicle Large - large vehicle (e.g. lorry, truck,bus), logistics vehicle\n",
    "    9 Vehicle Small - small vehicle (car, van), motorbike\n",
    "    '''\n",
    "    \n",
    "    return x, y, y_oneclass\n",
    "    \n",
    "    # Just use a single class: roads\n",
    "    #y = y[:,4,:,:]\n",
    "    #y = y[:,np.newaxis,:,:]\n",
    "\n",
    "    # y = y.reshape(y.shape[0],-1)\n",
    "    # x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def np_jaccard(y_true,y_pred,smooth=1.):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true * np.rint(y_pred))\n",
    "    return (intersection+smooth) / (np.sum(y_true) + np.sum(y_pred) - intersection+smooth)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
